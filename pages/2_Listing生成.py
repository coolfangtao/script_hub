import streamlit as st
import pandas as pd
import google.generativeai as genai
import textwrap

# --- å¯¼å…¥å…±äº«æ¨¡å— ---
# 1. ä»å…±äº«é…ç½®æ–‡ä»¶ä¸­å¯¼å…¥ GlobalConfig åŸºç±»
from shared.config import GlobalConfig
# å‡è®¾è¿™äº›æ¨¡å—å­˜åœ¨äºæ‚¨çš„é¡¹ç›®ç»“æ„ä¸­ (å¦‚æœä¸å­˜åœ¨ï¼Œå¯ä»¥æš‚æ—¶æ³¨é‡Šæ‰)
# from shared.usage_tracker import track_script_usage
from shared.sidebar import create_common_sidebar


# --- æœ¬åœ°é…ç½®ç±» ---
# 2. ListingConfig ç»§æ‰¿è‡ª GlobalConfig
class ListingConfig(GlobalConfig):
    """
    Listing æ™ºèƒ½ç”Ÿæˆå™¨çš„é…ç½®ç±»ã€‚
    ç»§æ‰¿ GlobalConfig ä»¥è·å–å…±äº«é…ç½®ï¼Œå¦‚ RUN_MODE å’Œ GEMINI_API_KEY åç§°ã€‚
    """

    def __init__(self):
        # åˆå§‹åŒ–çˆ¶ç±»ï¼Œä»¥è®¾ç½® RUN_MODE ç­‰å±æ€§
        super().__init__()

        # åº”ç”¨é…ç½®
        self.PAGE_TITLE = "Listing æ™ºèƒ½ç”Ÿæˆå™¨"
        self.PAGE_ICON = "ğŸ“"
        self.LAYOUT = "wide"

        # API é…ç½®
        # GEMINI_API_KEY å±æ€§å·²ä» GlobalConfig ç»§æ‰¿
        # è¦†ç›–çˆ¶ç±»çš„é»˜è®¤æ¨¡å‹ä»¥ä½¿ç”¨æ›´å…·ä½“çš„ç‰ˆæœ¬
        self.DEFAULT_MODEL = "gemini-2.5-pro"

        # --- æ–°å¢ï¼šå¯é€‰çš„ Gemini æ¨¡å‹åˆ—è¡¨ ---
        self.GEMINI_MODEL_OPTIONS = [
            "gemini-2.5-flash-lite",
            "gemini-2.0-flash",
            "gemini-2.5-pro",
            "gemini-2.0-flash-exp",
            "gemini-2.0-flash-lite",
            "gemini-2.5-flash",
            "gemini-robotics-er-1.5-preview",
        ]

        # æ•°æ®é…ç½®
        self.KEYWORD_COLUMNS = ['æµé‡è¯', 'å…³é”®è¯ç¿»è¯‘', 'æµé‡å æ¯”', 'æœˆæœç´¢é‡', 'è´­ä¹°ç‡', 'ASIN']
        self.TOP_N_KEYWORDS = 20

        # æç¤ºè¯æ¨¡æ¿ (ä¿æŒä¸å˜)
        self.TITLE_PROMPT_TEMPLATE = """
            ä½ æ˜¯ä¸€åä¸“ä¸šçš„äºšé©¬é€Šç¾å›½ç«™çš„ç”µå•†è¿è¥ä¸“å®¶ï¼Œå°¤å…¶æ“…é•¿æ’°å†™å¸å¼•äººçš„äº§å“æ ‡é¢˜ã€‚
            è¯·æ ¹æ®ä»¥ä¸‹å…³é”®è¯æ•°æ®ï¼Œä¸ºä¸€æ¬¾"{product_name}" ({product_english_name}) æ’°å†™ {title_count} ä¸ªç¬¦åˆäºšé©¬é€Šå¹³å°è§„åˆ™ä¸”å…·æœ‰é«˜å¸å¼•åŠ›çš„äº§å“æ ‡é¢˜ã€‚

            **å…³é”®è¯æ•°æ®å‚è€ƒ:**
            - **æµé‡å æ¯”æœ€é«˜çš„ TOP {top_n} å…³é”®è¯:**
            ```csv
            {traffic_keywords_csv}
            ```

            - **æœˆæœç´¢é‡æœ€é«˜çš„ TOP {top_n} å…³é”®è¯:**
            ```csv
            {search_volume_keywords_csv}
            ```

            **æ ‡é¢˜è¦æ±‚:**
            1.  **æ ¸å¿ƒå…³é”®è¯ä¼˜å…ˆ**: å¿…é¡»åŒ…å«æœ€æ ¸å¿ƒçš„å…³é”®è¯ï¼Œå¦‚ {core_keywords} ç­‰ã€‚
            2.  **çªå‡ºç‰¹æ€§å’Œä¼˜åŠ¿**: ç»“åˆå…³é”®è¯ï¼Œæç‚¼äº§å“çš„ä¸»è¦å–ç‚¹ï¼Œä¾‹å¦‚ {key_features}ã€‚
            3.  **å¯è¯»æ€§å¼º**: æ ‡é¢˜ç»“æ„æ¸…æ™°ï¼Œæ˜“äºæ¶ˆè´¹è€…å¿«é€Ÿç†è§£äº§å“æ˜¯ä»€ä¹ˆã€‚
            4.  **é•¿åº¦é€‚ä¸­**: æ ‡é¢˜æ€»é•¿åº¦å»ºè®®åœ¨ 150-200 ä¸ªå­—ç¬¦ä¹‹é—´ã€‚
            5.  **æ ¼å¼è§„èŒƒ**: æ¯ä¸ªå•è¯çš„é¦–å­—æ¯å¤§å†™ï¼ˆé™¤äº† a, an, the, and, but, for, in, on, at ç­‰è™šè¯ï¼‰ã€‚

            è¯·ç›´æ¥ç»™å‡ºä½ è®¤ä¸ºæœ€ä½³çš„ {title_count} ä¸ªäº§å“æ ‡é¢˜ï¼Œå¹¶ç”¨æ•°å­—ç¼–å·ã€‚
        """

        self.BULLET_POINTS_PROMPT_TEMPLATE = """
            ä½ æ˜¯ä¸€åä¸“ä¸šçš„äºšé©¬é€Šç¾å›½ç«™çš„æ–‡æ¡ˆä¸“å®¶ï¼Œæ“…é•¿æ’°å†™èƒ½å¤Ÿæå‡è½¬åŒ–ç‡çš„äº”ç‚¹æè¿° (Bullet Points)ã€‚
            è¯·æ ¹æ®ä»¥ä¸‹å…³é”®è¯æ•°æ®ï¼Œä¸ºä¸€æ¬¾"{product_name}" ({product_english_name}) æ’°å†™ {bullet_points_count} ç‚¹æè¿°ã€‚

            **å…³é”®è¯æ•°æ®å‚è€ƒ:**
            - **æµé‡å æ¯”æœ€é«˜çš„ TOP {top_n} å…³é”®è¯:**
            ```csv
            {traffic_keywords_csv}
            ```

            - **æœˆæœç´¢é‡æœ€é«˜çš„ TOP {top_n} å…³é”®è¯:**
            ```csv
            {search_volume_keywords_csv}
            ```

            **äº”ç‚¹æè¿°è¦æ±‚:**
            1.  **çªå‡ºå–ç‚¹**: æ¯ä¸€ç‚¹éƒ½åº”è¯¥èšç„¦ä¸€ä¸ªæ ¸å¿ƒå–ç‚¹æˆ–åŠŸèƒ½ï¼Œå¹¶è¯¦ç»†é˜è¿°å®ƒèƒ½ä¸ºå®¢æˆ·å¸¦æ¥çš„å¥½å¤„ã€‚
            2.  **æ ¼å¼æ¸…æ™°**: æ¯ä¸€ç‚¹çš„å¼€å¤´ä½¿ç”¨ä¸€ä¸ªç®€çŸ­ã€é†’ç›®çš„çŸ­è¯­æˆ–æ ‡é¢˜ (ä¾‹å¦‚ "{bullet_point_example}")ï¼Œå¹¶ç”¨å¤§å†™å­—æ¯å’Œç‰¹æ®Šç¬¦å·çªå‡ºï¼Œä½¿å…¶æ˜“äºé˜…è¯»ã€‚
            3.  **èå…¥å…³é”®è¯**: è‡ªç„¶åœ°å°†æ ¸å¿ƒå…³é”®è¯å’Œé•¿å°¾å…³é”®è¯èå…¥åˆ°æè¿°ä¸­ï¼Œä»¥æé«˜ SEO æƒé‡ã€‚
            4.  **è§£å†³ç”¨æˆ·ç—›ç‚¹**: è®¾æƒ³ç”¨æˆ·å¯èƒ½é‡åˆ°çš„é—®é¢˜ (å¦‚{user_pain_points})ï¼Œå¹¶åœ¨æè¿°ä¸­ç»™å‡ºè§£å†³æ–¹æ¡ˆã€‚
            5.  **è¦†ç›–å¤šç§ä½¿ç”¨åœºæ™¯**: æè¿°äº§å“å¯ä»¥ç”¨äº{usage_scenarios}ã€‚

            è¯·ä¸¥æ ¼æŒ‰ç…§ {bullet_points_count} ç‚¹çš„æ ¼å¼ï¼Œç»™å‡ºå®Œæ•´çš„äº”ç‚¹æè¿°ã€‚
        """

        # äº§å“ç‰¹å®šé…ç½® (ä¿æŒä¸å˜)
        self.PRODUCT_NAME = "å® ç‰©è„±æ¯›æ‰‹å¥—"
        self.PRODUCT_ENGLISH_NAME = "pet hair removal glove"
        self.CORE_KEYWORDS = "'pet hair remover glove', 'dog grooming glove', 'cat hair glove'"
        self.KEY_FEATURES = "'gentle', 'efficient', 'for cats and dogs'"
        self.BULLET_POINT_EXAMPLE = "ã€Efficient Hair Removalã€‘"
        self.USER_PAIN_POINTS = "å® ç‰©æ¯›å‘æ»¡å¤©é£ã€æ™®é€šæ¢³å­æ•ˆæœä¸ä½³ã€å® ç‰©ä¸å–œæ¬¢æ¢³æ¯›ç­‰"
        self.USAGE_SCENARIOS = "çŒ«ã€ç‹—ã€é•¿æ¯›æˆ–çŸ­æ¯›å® ç‰©ï¼Œä»¥åŠç”¨äºæ²™å‘ã€åœ°æ¯¯ç­‰åœºæ™¯"

        # ç”Ÿæˆæ•°é‡é…ç½® (ä¿æŒä¸å˜)
        self.TITLE_COUNT = 4
        self.BULLET_POINTS_COUNT = 5


# --- é¡µé¢é…ç½® ---
cfg = ListingConfig()
st.set_page_config(
    page_title=cfg.PAGE_TITLE,
    page_icon=cfg.PAGE_ICON,
    layout=cfg.LAYOUT
)

# åŠ è½½å…±äº«ä¾§è¾¹æ 
# track_script_usage("ğŸ“ Listingç”Ÿæˆ")
create_common_sidebar()


# --- ä¸»è¦åŠŸèƒ½å‡½æ•° (éƒ¨åˆ†å·²ä¿®æ”¹) ---

def load_data(uploaded_file):
    """ä»ç”¨æˆ·ä¸Šä¼ çš„ Excel æ–‡ä»¶ä¸­åŠ è½½æ•°æ®ã€‚"""
    st.info(f"æ­£åœ¨è¯»å–æ–‡ä»¶: `{uploaded_file.name}`")
    try:
        df = pd.read_excel(uploaded_file, sheet_name=0)
        st.success("âœ… æ–‡ä»¶è¯»å–æˆåŠŸï¼")
        return df
    except Exception as e:
        st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
        return None


def preprocess_keyword_data(df: pd.DataFrame, config: ListingConfig):
    """é¢„å¤„ç†å…³é”®è¯æ•°æ®ï¼Œå¤„ç†å¤šASINçš„æƒ…å†µã€‚"""
    if 'ASIN' not in df.columns:
        st.warning("æ•°æ®ä¸­æœªæ‰¾åˆ°'ASIN'åˆ—ï¼Œå°†ä½¿ç”¨åŸå§‹æ•°æ®è¿›è¡Œå¤„ç†ã€‚")
        return df

    unique_asins = df['ASIN'].nunique()
    unique_keywords = df['æµé‡è¯'].nunique()
    st.info(f"ğŸ“Š æ•°æ®æ¦‚è§ˆ: å…± {len(df)} è¡Œæ•°æ®ï¼Œæ¶‰åŠ {unique_asins} ä¸ªASINï¼Œ{unique_keywords} ä¸ªå”¯ä¸€å…³é”®è¯")

    aggregation_rules = {}
    if 'æµé‡å æ¯”' in df.columns:
        df['æµé‡å æ¯”'] = pd.to_numeric(df['æµé‡å æ¯”'], errors='coerce')
        aggregation_rules['æµé‡å æ¯”'] = 'max'
    if 'æœˆæœç´¢é‡' in df.columns:
        df['æœˆæœç´¢é‡'] = pd.to_numeric(df['æœˆæœç´¢é‡'], errors='coerce')
        aggregation_rules['æœˆæœç´¢é‡'] = 'first'
    if 'è´­ä¹°ç‡' in df.columns:
        df['è´­ä¹°ç‡'] = pd.to_numeric(df['è´­ä¹°ç‡'], errors='coerce')
        aggregation_rules['è´­ä¹°ç‡'] = 'mean'

    text_columns = ['æµé‡è¯', 'å…³é”®è¯ç¿»è¯‘']
    for col in text_columns:
        if col in df.columns:
            aggregation_rules[col] = 'first'

    if aggregation_rules:
        processed_df = df.groupby('æµé‡è¯', as_index=False).agg(aggregation_rules)
        col1, col2 = st.columns(2)
        with col1:
            st.metric("å¤„ç†å‰æ•°æ®è¡Œæ•°", len(df))
        with col2:
            st.metric("å¤„ç†åå”¯ä¸€å…³é”®è¯æ•°", len(processed_df))
        return processed_df
    else:
        return df


def get_top_keywords_by_traffic(df: pd.DataFrame, config: ListingConfig):
    """è·å–æµé‡å æ¯”æœ€é«˜çš„å…³é”®è¯ã€‚"""
    if 'æµé‡å æ¯”' in df.columns:
        df_copy = df.copy()
        df_copy['æµé‡å æ¯”'] = pd.to_numeric(df_copy['æµé‡å æ¯”'], errors='coerce')
        df_copy.dropna(subset=['æµé‡å æ¯”'], inplace=True)
        top_traffic_df = df_copy.sort_values(by='æµé‡å æ¯”', ascending=False).head(config.TOP_N_KEYWORDS)
        return top_traffic_df
    else:
        st.warning("æ•°æ®ä¸­æœªæ‰¾åˆ°'æµé‡å æ¯”'åˆ—ï¼Œå°†ä½¿ç”¨å‰20è¡Œæ•°æ®ä½œä¸ºæµé‡å…³é”®è¯ã€‚")
        return df.head(config.TOP_N_KEYWORDS)


def get_top_keywords_by_search_volume(df: pd.DataFrame, config: ListingConfig):
    """è·å–æœˆæœç´¢é‡æœ€é«˜çš„å…³é”®è¯ã€‚"""
    if 'æœˆæœç´¢é‡' in df.columns:
        df_copy = df.copy()
        df_copy['æœˆæœç´¢é‡'] = pd.to_numeric(df_copy['æœˆæœç´¢é‡'], errors='coerce')
        df_copy.dropna(subset=['æœˆæœç´¢é‡'], inplace=True)
        top_search_df = df_copy.sort_values(by='æœˆæœç´¢é‡', ascending=False).head(config.TOP_N_KEYWORDS)
        return top_search_df
    else:
        st.warning("æ•°æ®ä¸­æœªæ‰¾åˆ°'æœˆæœç´¢é‡'åˆ—ï¼Œå°†ä½¿ç”¨æµé‡å æ¯”æ•°æ®æ›¿ä»£ã€‚")
        return get_top_keywords_by_traffic(df, config)


def create_prompts(df: pd.DataFrame, config: ListingConfig):
    """æ ¹æ® DataFrame ä¸­çš„å…³é”®è¯æ•°æ®ï¼Œåˆ›å»ºç”¨äºç”Ÿæˆæ ‡é¢˜å’Œäº”ç‚¹æè¿°çš„æç¤ºè¯ã€‚"""
    processed_df = preprocess_keyword_data(df, config)
    top_traffic_df = get_top_keywords_by_traffic(processed_df, config)
    top_search_df = get_top_keywords_by_search_volume(processed_df, config)

    existing_columns = [col for col in config.KEYWORD_COLUMNS if col in processed_df.columns and col != 'ASIN']
    traffic_keywords_csv = top_traffic_df[existing_columns].to_csv(index=False)
    search_volume_keywords_csv = top_search_df[existing_columns].to_csv(index=False)

    title_prompt = textwrap.dedent(config.TITLE_PROMPT_TEMPLATE.format(
        top_n=config.TOP_N_KEYWORDS, product_name=config.PRODUCT_NAME,
        product_english_name=config.PRODUCT_ENGLISH_NAME, title_count=config.TITLE_COUNT,
        core_keywords=config.CORE_KEYWORDS, key_features=config.KEY_FEATURES,
        traffic_keywords_csv=traffic_keywords_csv, search_volume_keywords_csv=search_volume_keywords_csv
    )).strip()

    bullet_points_prompt = textwrap.dedent(config.BULLET_POINTS_PROMPT_TEMPLATE.format(
        top_n=config.TOP_N_KEYWORDS, product_name=config.PRODUCT_NAME,
        product_english_name=config.PRODUCT_ENGLISH_NAME, bullet_points_count=config.BULLET_POINTS_COUNT,
        bullet_point_example=config.BULLET_POINT_EXAMPLE, user_pain_points=config.USER_PAIN_POINTS,
        usage_scenarios=config.USAGE_SCENARIOS, traffic_keywords_csv=traffic_keywords_csv,
        search_volume_keywords_csv=search_volume_keywords_csv
    )).strip()

    return {
        "title": title_prompt, "bullet_points": bullet_points_prompt, "top_traffic_df": top_traffic_df,
        "top_search_df": top_search_df, "processed_df": processed_df
    }


# --- ä¿®æ”¹ï¼šgenerate_listing_info å‡½æ•°ç°åœ¨æ¥æ”¶ model_name å‚æ•° ---
def generate_listing_info(api_key: str, prompt: str, model_name: str):
    """ä½¿ç”¨ Google Gemini API æ ¹æ®æç¤ºè¯ç”Ÿæˆå†…å®¹ã€‚"""
    if not api_key or not api_key.startswith("AI"):
        st.error("âŒ Google Gemini API å¯†é’¥æ— æ•ˆæˆ–æœªæä¾›ï¼Œè¯·æ£€æŸ¥ã€‚")
        return None
    try:
        genai.configure(api_key=api_key)
        # ä½¿ç”¨ä¼ å…¥çš„ model_name åˆå§‹åŒ–æ¨¡å‹
        model = genai.GenerativeModel(model_name)
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        st.error(f"è°ƒç”¨ API æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return f"è°ƒç”¨APIæ—¶å‘ç”Ÿé”™è¯¯: {e}"


# --- ä¸»å‡½æ•°ä¸é¡µé¢æ¸²æŸ“ (å·²é‡æ„ä»¥æ”¯æŒé¡µé¢æŒä¹…åŒ–å’Œæ¨¡å‹é€‰æ‹©) ---

def main():
    """
    Streamlit åº”ç”¨çš„ä¸»å‡½æ•°ï¼Œè´Ÿè´£æ¸²æŸ“æ•´ä¸ªé¡µé¢ã€‚
    é€šè¿‡ session_state å®ç°äº†é¡µé¢åˆ‡æ¢åçš„çŠ¶æ€ä¿æŒã€‚
    """
    st.title(cfg.PAGE_TITLE)
    st.markdown("ä¸Šä¼ å…³é”®è¯åæŸ¥æŠ¥å‘Šï¼ŒAI åŠ©æ‚¨ä¸€é”®ç”Ÿæˆé«˜è´¨é‡çš„äºšé©¬é€Šå•†å“æ ‡é¢˜å’Œäº”ç‚¹æè¿°ã€‚")

    # --- åˆå§‹åŒ– Session State ---
    # åœ¨åº”ç”¨å¼€å§‹æ—¶ï¼Œç¡®ä¿æ‰€æœ‰éœ€è¦çš„é”®éƒ½å­˜åœ¨äº session_state ä¸­
    if 'uploaded_filename' not in st.session_state:
        st.session_state.uploaded_filename = None
    if 'uploaded_data' not in st.session_state:
        st.session_state.uploaded_data = None
    if 'generated_prompts' not in st.session_state:
        st.session_state.generated_prompts = None
    if 'generated_title' not in st.session_state:
        st.session_state.generated_title = None
    if 'generated_bullets' not in st.session_state:
        st.session_state.generated_bullets = None
    # --- æ–°å¢ï¼šä¸ºé€‰æ‹©çš„æ¨¡å‹åˆå§‹åŒ– session_state ---
    if 'selected_model' not in st.session_state:
        st.session_state.selected_model = cfg.DEFAULT_MODEL

    # æ ¹æ®è¿è¡Œæ¨¡å¼å¤„ç† API Key
    api_key = None
    if cfg.RUN_MODE == "cloud":
        st.info("â˜ï¸ æ‚¨æ­£åœ¨äº‘ç«¯è¿è¡Œæœ¬åº”ç”¨ï¼Œè¯·è¾“å…¥æ‚¨çš„ Google Gemini API å¯†é’¥ä»¥ç»§ç»­ã€‚")
        api_key = st.text_input(
            "åœ¨æ­¤è¾“å…¥æ‚¨çš„ Google Gemini API Key",
            type="password",
            help="æ‚¨çš„å¯†é’¥ä¸ä¼šè¢«å‚¨å­˜æˆ–åˆ†äº«ã€‚"
        )
    else:  # local mode
        st.info("ğŸ¡ æ‚¨æ­£åœ¨æœ¬åœ°è¿è¡Œæœ¬åº”ç”¨ï¼Œå°†ä» secrets.toml æ–‡ä»¶åŠ è½½ API å¯†é’¥ã€‚")
        api_key = st.secrets.get(cfg.GEMINI_API_KEY)

    # æ£€æŸ¥ API Key æ˜¯å¦æœ‰æ•ˆï¼Œå¦‚æœæ— æ•ˆåˆ™é˜»æ­¢åç»­æ“ä½œ
    if not api_key:
        st.warning("è¯·è¾“å…¥æˆ–é…ç½®æ‚¨çš„ API å¯†é’¥ä»¥å¼€å§‹ä½¿ç”¨ã€‚")
        st.stop()

    # --- æ­¥éª¤ 1: ä¸Šä¼ æ–‡ä»¶ä¸æ•°æ®å¤„ç† ---
    with st.container(border=True):
        st.header("âš™ï¸ ç¬¬ 1 æ­¥: ä¸Šä¼ æ–‡ä»¶ä¸é…ç½®")

        # --- æ–°å¢ï¼šæ¨¡å‹é€‰æ‹©å™¨ ---
        # ä½¿ç”¨ key ç›´æ¥å°†é€‰æ‹©å™¨çš„å€¼ç»‘å®šåˆ° session_state
        st.selectbox(
            label="é€‰æ‹©æ‚¨æƒ³ä½¿ç”¨çš„ AI æ¨¡å‹:",
            options=cfg.GEMINI_MODEL_OPTIONS,
            # ç¡®ä¿é»˜è®¤é€‰é¡¹æ˜¯é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šçš„æ¨¡å‹
            index=cfg.GEMINI_MODEL_OPTIONS.index(st.session_state.selected_model),
            key='selected_model',
            help="æ¨¡å‹è¶Šå¼ºå¤§ï¼Œç”Ÿæˆé€Ÿåº¦å¯èƒ½è¶Šæ…¢ï¼Œæˆæœ¬ä¹Ÿå¯èƒ½æ›´é«˜ã€‚"
        )

        uploaded_file = st.file_uploader(
            "ä¸Šä¼ æ‚¨çš„å…³é”®è¯åæŸ¥ Excel æ–‡ä»¶",
            type=['xlsx'],
            help="ä¸Šä¼ æ–°æ–‡ä»¶å°†ä¼šè¦†ç›–å½“å‰å·²åŠ è½½çš„æ•°æ®ï¼Œå¹¶é‡ç½®ç”Ÿæˆæµç¨‹ã€‚"
        )

        # æ ¸å¿ƒé€»è¾‘ï¼šä»…å½“ä¸Šä¼ äº†â€œæ–°â€æ–‡ä»¶æ—¶ï¼Œæ‰æ‰§è¡Œæ•°æ®å¤„ç†å’ŒçŠ¶æ€é‡ç½®
        if uploaded_file is not None and uploaded_file.name != st.session_state.uploaded_filename:
            df = load_data(uploaded_file)
            if df is not None:
                # 1. ç¼“å­˜æ–°æ•°æ®å’Œæ–°æ–‡ä»¶å
                st.session_state.uploaded_data = df
                st.session_state.uploaded_filename = uploaded_file.name
                # 2. é‡ç½®æ‰€æœ‰ä¸‹æ¸¸çŠ¶æ€ï¼Œå› ä¸ºæºæ•°æ®å·²æ›´æ”¹
                st.session_state.generated_prompts = None
                st.session_state.generated_title = None
                st.session_state.generated_bullets = None
                # ä½¿ç”¨ st.rerun() å¯ä»¥ç«‹å³åˆ·æ–°é¡µé¢ï¼Œæä¾›æ›´æµç•…çš„ä½“éªŒ
                st.rerun()

        # UIæ¸²æŸ“é€»è¾‘ï¼šå®Œå…¨åŸºäº session_state ä¸­çš„æ•°æ®çŠ¶æ€
        if st.session_state.uploaded_data is not None:
            st.success(f"âœ… å½“å‰å·²åŠ è½½æ•°æ®æ–‡ä»¶: **{st.session_state.uploaded_filename}**")
            with st.expander("ğŸ“Š ç‚¹å‡»æŸ¥çœ‹å®Œæ•´æ•°æ®"):
                df_display = st.session_state.uploaded_data
                st.dataframe(df_display, use_container_width=True)
                st.markdown(f"**æ•°æ®æ€»è¡Œæ•°:** {len(df_display)} è¡Œ")
                if 'ASIN' in df_display.columns:
                    st.markdown(f"**æ¶‰åŠASINæ•°é‡:** {df_display['ASIN'].nunique()} ä¸ª")

            # ä»…å½“æç¤ºè¯å°šæœªç”Ÿæˆæ—¶ï¼Œæ‰æ˜¾ç¤ºâ€œç”Ÿæˆæç¤ºè¯â€æŒ‰é’®
            if st.session_state.generated_prompts is None:
                if st.button("ğŸ“ åˆ†ææ•°æ®å¹¶ç”Ÿæˆæç¤ºè¯", type="primary"):
                    with st.spinner("æ­£åœ¨åˆ†æå…³é”®è¯å¹¶åˆ›å»ºæç¤ºè¯..."):
                        prompts_data = create_prompts(st.session_state.uploaded_data, cfg)
                        st.session_state.generated_prompts = prompts_data
                    st.success("âœ… æç¤ºè¯å·²åœ¨ä¸‹æ–¹ç”Ÿæˆï¼æ‚¨å¯ä»¥è¿›è¡Œä¿®æ”¹ã€‚")
                    st.rerun()
        else:
            st.info("è¯·å…ˆä¸Šä¼ æ‚¨çš„ Excel æ–‡ä»¶ä»¥å¼€å§‹ã€‚")

    # --- æ­¥éª¤ 2: ç¼–è¾‘æç¤ºè¯ ---
    if st.session_state.generated_prompts:
        with st.container(border=True):
            st.header("âœï¸ ç¬¬ 2 æ­¥: å®¡æ ¸å¹¶ä¼˜åŒ–æç¤ºè¯")
            st.markdown("æ‚¨å¯ä»¥åœ¨æ­¤å¾®è°ƒAIçš„æŒ‡ä»¤ã€‚ä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥è¦æ±‚ç”Ÿæˆ 5 ä¸ªè€Œä¸æ˜¯ 4 ä¸ªæ ‡é¢˜ï¼Œæˆ–è€…æ”¹å˜æ–‡æ¡ˆçš„è¯­æ°”ã€‚")

            if 'processed_df' in st.session_state.generated_prompts:
                processed_df = st.session_state.generated_prompts['processed_df']
                st.info(f"ğŸ”§ æ•°æ®å·²é¢„å¤„ç†ï¼šä» {len(st.session_state.uploaded_data)} è¡ŒåŸå§‹æ•°æ®èšåˆä¸º {len(processed_df)} ä¸ªå”¯ä¸€å…³é”®è¯")

            st.subheader("ğŸ“‹ æå–çš„å…³é”®è¯æ•°æ®")
            col1, col2 = st.columns(2)
            with col1:
                st.markdown(f"**ğŸ” æµé‡å æ¯” TOP {cfg.TOP_N_KEYWORDS} å…³é”®è¯**")
                top_traffic_df = st.session_state.generated_prompts.get('top_traffic_df')
                if top_traffic_df is not None:
                    display_columns = [col for col in cfg.KEYWORD_COLUMNS if
                                       col in top_traffic_df.columns and col != 'ASIN']
                    st.dataframe(top_traffic_df[display_columns], use_container_width=True, height=400)
                    st.markdown(f"*å…± {len(top_traffic_df)} ä¸ªå…³é”®è¯*")

            with col2:
                st.markdown(f"**ğŸ” æœˆæœç´¢é‡ TOP {cfg.TOP_N_KEYWORDS} å…³é”®è¯**")
                top_search_df = st.session_state.generated_prompts.get('top_search_df')
                if top_search_df is not None:
                    display_columns = [col for col in cfg.KEYWORD_COLUMNS if
                                       col in top_search_df.columns and col != 'ASIN']
                    st.dataframe(top_search_df[display_columns], use_container_width=True, height=400)
                    st.markdown(f"*å…± {len(top_search_df)} ä¸ªå…³é”®è¯*")

            st.divider()
            st.subheader("ğŸ› ï¸ æç¤ºè¯ç¼–è¾‘")
            col1, col2 = st.columns(2)
            with col1:
                title_prompt_text = st.text_area(
                    label="**æ ‡é¢˜ç”Ÿæˆæç¤ºè¯ (Title Prompt)**",
                    value=st.session_state.generated_prompts['title'],
                    height=500,
                    key='title_prompt_editor'
                )
            with col2:
                bullet_points_prompt_text = st.text_area(
                    label="**äº”ç‚¹æè¿°ç”Ÿæˆæç¤ºè¯ (Bullet Points Prompt)**",
                    value=st.session_state.generated_prompts['bullet_points'],
                    height=500,
                    key='bullets_prompt_editor'
                )

            st.header("âœ¨ ç¬¬ 3 æ­¥: ç”Ÿæˆ Listing")
            if st.button("ğŸš€ ç‚¹å‡»ç”Ÿæˆ Listing", type="primary", use_container_width=True):
                # --- ä¿®æ”¹ï¼šæ›´æ–° spinner æç¤ºä¿¡æ¯ ---
                spinner_message = f"AI æ­£åœ¨ä½¿ç”¨ `{st.session_state.selected_model}` æ¨¡å‹åŠªåŠ›åˆ›ä½œä¸­ï¼Œè¯·ç¨å€™..."
                with st.spinner(spinner_message):
                    # ä»ç¼–è¾‘æ¡†è·å–æœ€æ–°æ–‡æœ¬
                    final_title_prompt = st.session_state.title_prompt_editor
                    final_bullets_prompt = st.session_state.bullets_prompt_editor

                    # --- ä¿®æ”¹ï¼šå°†é€‰æ‹©çš„æ¨¡å‹åç§°ä¼ å…¥ç”Ÿæˆå‡½æ•° ---
                    selected_model = st.session_state.selected_model
                    generated_title = generate_listing_info(api_key, final_title_prompt, selected_model)
                    generated_bullets = generate_listing_info(api_key, final_bullets_prompt, selected_model)

                    st.session_state.generated_title = generated_title
                    st.session_state.generated_bullets = generated_bullets
                st.rerun()

    # --- ç»“æœå±•ç¤º ---
    if 'generated_title' in st.session_state and st.session_state.generated_title:
        with st.container(border=True):
            st.header("âœ… ç¬¬ 4 æ­¥: æŸ¥çœ‹å¹¶å¤åˆ¶ç»“æœ")
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**å»ºè®®æ ‡é¢˜:**")
                st.code(st.session_state.generated_title, language=None)
            with col2:
                st.markdown("**å»ºè®®äº”ç‚¹æè¿°:**")
                st.code(st.session_state.generated_bullets, language=None)


if __name__ == "__main__":
    main()