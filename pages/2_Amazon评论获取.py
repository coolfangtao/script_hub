import streamlit as st
import json
import re
import requests
import io
import zipfile
from urllib.parse import urlparse
import os


# --- Helper Function ---
def convert_to_hd_url(thumbnail_url):
    """
    å°†äºšé©¬é€Šç¼©ç•¥å›¾URLè½¬æ¢ä¸ºé«˜æ¸…å›¾URLã€‚
    ä¾‹å¦‚: .../I/71HE2s0wqhL._SY88_.jpg -> .../I/71HE2s0wqhL.jpg
    """
    # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…URLæœ«å°¾çš„ "._..._" éƒ¨åˆ†
    # \.   -> åŒ¹é…ç‚¹ .
    # _    -> åŒ¹é…ä¸‹åˆ’çº¿ _
    # [A-Z0-9]+ -> åŒ¹é…ä¸€ä¸ªæˆ–å¤šä¸ªå¤§å†™å­—æ¯æˆ–æ•°å­— (å¦‚ SY88, AC_SL1500)
    # _?   -> åŒ¹é…ä¸€ä¸ªå¯é€‰çš„ä¸‹åˆ’çº¿ (æœ‰äº›é“¾æ¥æœ«å°¾æ˜¯ ._SY88.jpg è€Œä¸æ˜¯ ._SY88_.jpg)
    # (?=\.) -> æ­£å‘å…ˆè¡Œæ–­è¨€ï¼Œç¡®ä¿åé¢è·Ÿç€ä¸€ä¸ªç‚¹ï¼ˆæ–‡ä»¶æ‰©å±•åçš„ç‚¹ï¼‰
    pattern = r'\._[A-Z0-9_]+_\.'

    # ç®€å•çš„æ›¿æ¢æ–¹æ³•ï¼Œæ›´ç¬¦åˆæè¿°
    # æ‰¾åˆ°æœ€åä¸€ä¸ªç‚¹ï¼ˆæ‰©å±•åå‰ï¼‰å’Œå®ƒä¹‹å‰çš„ç‚¹
    parts = thumbnail_url.split('.')
    if len(parts) > 2 and parts[-2].startswith('_') and parts[-2].endswith('_'):
        # ç§»é™¤ `_SY88_` è¿™æ ·çš„éƒ¨åˆ†
        base_url = ".".join(parts[:-2])
        extension = parts[-1]
        return f"{base_url}.{extension}"

    # å¦‚æœä¸Šé¢çš„ç®€å•æ–¹æ³•ä¸å¥æ•ˆï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä½œä¸ºå¤‡ç”¨
    hd_url = re.sub(r'\._.*?_\.', '.', thumbnail_url)
    if hd_url == thumbnail_url:  # å¦‚æœæ­£åˆ™æ²¡æ›¿æ¢æˆåŠŸï¼Œå°è¯•å¦ä¸€ç§æ¨¡å¼
        hd_url = re.sub(r'\._[A-Z0-9_]+\.', '.', thumbnail_url)

    return hd_url


# --- Streamlit App ---

st.set_page_config(page_title="äºšé©¬é€Šè¯„è®ºåˆ†æå™¨", layout="wide")

st.title("ğŸ“¦ äºšé©¬é€Šè¯„è®ºå›¾ç‰‡æŸ¥çœ‹ä¸ä¸‹è½½å·¥å…·")
st.write("ä¸Šä¼ ä»çˆ¬è™«å·¥å…·å¯¼å‡ºçš„JSONæ–‡ä»¶ï¼Œå³å¯æŸ¥çœ‹è¯„è®ºè¯¦æƒ…å¹¶ä¸€é”®ä¸‹è½½æ‰€æœ‰é«˜æ¸…å›¾ç‰‡ã€‚")

uploaded_file = st.file_uploader("è¯·åœ¨è¿™é‡Œä¸Šä¼ æ‚¨çš„ JSON æ–‡ä»¶", type="json")

if uploaded_file is not None:
    try:
        # è¯»å–å¹¶è§£æJSONæ–‡ä»¶
        data = json.load(uploaded_file)

        # --- 1. å±•ç¤ºäº§å“æ€»è§ˆä¿¡æ¯ ---
        st.header("ğŸ“Š äº§å“æ€»è§ˆ")
        product_info = data.get("product", {})
        title = product_info.get("title", "N/A")
        price = product_info.get("price", "N/A")
        url = product_info.get("url", "#")
        total_reviews = data.get("totalReviewsExtracted", "N/A")

        col1, col2 = st.columns(2)
        with col1:
            st.markdown(f"**äº§å“æ ‡é¢˜:** [{title}]({url})")
            st.markdown(f"**äº§å“ä»·æ ¼:** `{price}`")
            st.markdown(f"**å·²æå–è¯„è®ºæ•°:** `{total_reviews}`")
        with col2:
            # å¯ä»¥åœ¨è¿™é‡Œæ”¾äº§å“ä¸»å›¾ï¼Œå¦‚æœJSONé‡Œæœ‰çš„è¯
            st.info("è¿™é‡Œæ˜¯äº§å“çš„åŸºæœ¬ä¿¡æ¯ã€‚")

        # --- 2. å¾ªç¯å±•ç¤ºè¯„è®ºå’Œå›¾ç‰‡ ---
        st.header("ğŸ’¬ è¯„è®ºè¯¦æƒ…")

        all_images_to_download = []  # å­˜å‚¨æ‰€æœ‰é«˜æ¸…å›¾ä¿¡æ¯ (url, filename)

        reviews = data.get("reviews", [])
        if not reviews:
            st.warning("JSONæ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°'reviews'åˆ—è¡¨ã€‚")
        else:
            for review in reviews:
                st.markdown("---")
                reviewer_name = review.get('reviewerName', 'åŒ¿åç”¨æˆ·')
                rating = review.get('rating', 'æ— è¯„åˆ†')
                review_text = review.get('text', 'æ— è¯„è®ºå†…å®¹')
                review_id = review.get('reviewId', 'no_id')

                st.markdown(f"#### è¯„è®ºè€…: **{reviewer_name}** | è¯„åˆ†: **{rating}**")
                st.markdown(f"> {review_text}")

                image_urls = review.get('imageUrls', [])
                if image_urls:
                    cols = st.columns(len(image_urls))  # ä¸ºæ¯å¼ å›¾ç‰‡åˆ›å»ºä¸€ä¸ªåˆ—
                    for i, thumbnail_url in enumerate(image_urls):
                        hd_url = convert_to_hd_url(thumbnail_url)

                        # ä¸ºä¸‹è½½åŠŸèƒ½å‡†å¤‡æ•°æ®
                        # ä»URLä¸­æå–æ–‡ä»¶åï¼Œä¾‹å¦‚: 71HE2s0wqhL.jpg
                        try:
                            path = urlparse(hd_url).path
                            original_filename = os.path.basename(path)
                            # åˆ›å»ºä¸€ä¸ªå”¯ä¸€çš„æ–‡ä»¶å
                            filename = f"{review_id}_{i}_{original_filename}"
                            all_images_to_download.append({"url": hd_url, "filename": filename})
                        except Exception:
                            # å¦‚æœè§£æå¤±è´¥ï¼Œç»™ä¸€ä¸ªé»˜è®¤åå­—
                            filename = f"{review_id}_{i}.jpg"
                            all_images_to_download.append({"url": hd_url, "filename": filename})

                        with cols[i]:
                            st.image(hd_url, caption=f"é«˜æ¸…å›¾ç‰‡ (ç‚¹å‡»æ”¾å¤§)", use_column_width=True)

        # --- 3. æä¾›ä¸€é”®ä¸‹è½½æ‰€æœ‰å›¾ç‰‡çš„åŠŸèƒ½ ---
        st.header("ğŸ“¥ ä¸‹è½½æ‰€æœ‰å›¾ç‰‡")
        if all_images_to_download:
            st.info(f"åœ¨æ‰€æœ‰è¯„è®ºä¸­æ€»å…±æ‰¾åˆ°äº† **{len(all_images_to_download)}** å¼ å›¾ç‰‡ã€‚")

            if st.button("æ‰“åŒ…ä¸‹è½½æ‰€æœ‰é«˜æ¸…å›¾ç‰‡ (ZIP)"):
                # åˆ›å»ºä¸€ä¸ªå†…å­˜ä¸­çš„äºŒè¿›åˆ¶æµ
                zip_buffer = io.BytesIO()

                # åˆ›å»ºä¸€ä¸ªZipFileå¯¹è±¡
                with zipfile.ZipFile(zip_buffer, "a", zipfile.ZIP_DEFLATED, False) as zip_file:
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    total_images = len(all_images_to_download)

                    for i, img_data in enumerate(all_images_to_download):
                        try:
                            # ä¸‹è½½å›¾ç‰‡
                            response = requests.get(img_data["url"], timeout=10)
                            response.raise_for_status()  # å¦‚æœä¸‹è½½å¤±è´¥ï¼Œä¼šæŠ›å‡ºå¼‚å¸¸

                            # å°†å›¾ç‰‡æ•°æ®å†™å…¥zipæ–‡ä»¶
                            zip_file.writestr(img_data["filename"], response.content)

                            # æ›´æ–°è¿›åº¦æ¡
                            progress_percentage = (i + 1) / total_images
                            progress_bar.progress(progress_percentage)
                            status_text.text(f"æ­£åœ¨ä¸‹è½½å¹¶å‹ç¼©å›¾ç‰‡: {i + 1}/{total_images} ({img_data['filename']})")

                        except requests.exceptions.RequestException as e:
                            st.warning(f"ä¸‹è½½å›¾ç‰‡ {img_data['url']} å¤±è´¥: {e}")

                # å‡†å¤‡ä¸‹è½½æŒ‰é’®
                zip_buffer.seek(0)
                st.download_button(
                    label="âœ… ç‚¹å‡»è¿™é‡Œä¸‹è½½ZIPæ–‡ä»¶",
                    data=zip_buffer,
                    file_name=f"{title[:30]}_review_images.zip",  # ä½¿ç”¨äº§å“æ ‡é¢˜åšæ–‡ä»¶å
                    mime="application/zip"
                )
                status_text.success("å›¾ç‰‡å·²æ‰“åŒ…å®Œæˆï¼")

        else:
            st.warning("åœ¨è¯„è®ºä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å›¾ç‰‡å¯ä¾›ä¸‹è½½ã€‚")

    except json.JSONDecodeError:
        st.error("ä¸Šä¼ çš„æ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹ã€‚")
    except Exception as e:
        st.error(f"å¤„ç†æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")