import streamlit as st
import re
import os
from datetime import datetime
from typing import List, Tuple, Dict
from shared.sidebar import create_common_sidebar  # å¯¼å…¥å…¬å…±ä¾§è¾¹æ å‡½æ•°
create_common_sidebar()


def remove_suffix(text):
    """
    ä»å¤šè¡Œæ–‡æœ¬ä¸­å»é™¤å°¾ç¼€

    å‚æ•°:
        text: å¤šè¡Œæ–‡æœ¬å­—ç¬¦ä¸²

    è¿”å›:
        å»é™¤å°¾ç¼€åçš„æ–‡æœ¬å­—ç¬¦ä¸²
    """
    if not text:
        return ""

    # æŒ‰è¡Œåˆ†å‰²æ–‡æœ¬
    lines = text.splitlines()

    # æ‰¾åˆ°æœ€åä¸€ä¸ªéç©ºè¡Œçš„ç´¢å¼•
    last_non_empty_index = -1
    for i in range(len(lines) - 1, -1, -1):
        if lines[i].strip():  # æ£€æŸ¥è¡Œæ˜¯å¦éç©ºï¼ˆå»é™¤ç©ºç™½å­—ç¬¦åï¼‰
            last_non_empty_index = i
            break

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°éç©ºè¡Œï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
    if last_non_empty_index == -1:
        return ""

    # ä¿ç•™ä»å¼€å§‹åˆ°æœ€åä¸€ä¸ªéç©ºè¡Œä¹‹å‰çš„æ‰€æœ‰è¡Œ
    # æ³¨æ„ï¼šæœ€åä¸€ä¸ªéç©ºè¡Œæœ¬èº«ä¹Ÿè¦åˆ é™¤ï¼Œå› ä¸ºå®ƒæ˜¯å°¾ç¼€
    result_lines = lines[:last_non_empty_index]

    # å°†ç»“æœè¡Œé‡æ–°ç»„åˆæˆå­—ç¬¦ä¸²
    return '\n'.join(result_lines)


def extract_book_title(text):
    """
    ä»å¤šè¡Œæ–‡æœ¬ä¸­æå–ä¹¦å

    å‚æ•°:
    text (str): å¤šè¡Œæ–‡æœ¬

    è¿”å›:
    tuple: (ä¹¦å, å‰©ä½™æ–‡æœ¬)
    """
    lines = text.splitlines()

    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªéç©ºè¡Œ
    title_line = None
    title_index = -1

    for i, line in enumerate(lines):
        if line.strip():  # å¦‚æœä¸æ˜¯ç©ºè¡Œ
            title_line = line.strip()
            title_index = i
            break

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°éç©ºè¡Œï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
    if title_line is None:
        return "", ""

    # åˆ é™¤ä¹¦åè¡ŒåŠä¹‹å‰çš„æ‰€æœ‰è¡Œï¼Œä¿ç•™å‰©ä½™è¡Œ
    remaining_lines = lines[title_index + 1:]
    remaining_text = "\n".join(remaining_lines)

    return title_line, remaining_text


def extract_author_name(text):
    """
    ä»å¤šè¡Œæ–‡æœ¬ä¸­æå–ä½œè€…å

    å‚æ•°:
    text (str): å¤šè¡Œæ–‡æœ¬

    è¿”å›:
    tuple: (ä½œè€…å, å‰©ä½™æ–‡æœ¬)
    """
    lines = text.splitlines()

    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªéç©ºè¡Œ
    author_name = ""
    author_index = -1

    for i, line in enumerate(lines):
        if line.strip():  # å¦‚æœä¸æ˜¯ç©ºè¡Œ
            author_name = line.strip()
            author_index = i
            break

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°éç©ºè¡Œï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
    if author_index == -1:
        return "", ""

    # åˆ é™¤ä½œè€…åè¡ŒåŠä¹‹å‰çš„æ‰€æœ‰è¡Œï¼Œä¿ç•™å‰©ä½™è¡Œ
    remaining_lines = lines[author_index + 1:]
    remaining_text = "\n".join(remaining_lines)

    return author_name, remaining_text


def extract_note_count(text):
    """
    ä»å¤šè¡Œæ–‡æœ¬ä¸­æå–ç¬”è®°æ•°

    å‚æ•°:
    text (str): å¤šè¡Œæ–‡æœ¬

    è¿”å›:
    tuple: (ç¬”è®°æ•°, å‰©ä½™æ–‡æœ¬)
    """
    lines = text.splitlines()

    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªéç©ºè¡Œ
    note_count = ""
    note_index = -1

    for i, line in enumerate(lines):
        if line.strip():  # å¦‚æœä¸æ˜¯ç©ºè¡Œ
            note_count = line.strip()
            note_index = i
            break

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°éç©ºè¡Œï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
    if note_index == -1:
        return "", ""

    # åˆ é™¤ç¬”è®°æ•°è¡ŒåŠä¹‹å‰çš„æ‰€æœ‰è¡Œï¼Œä¿ç•™å‰©ä½™è¡Œ
    remaining_lines = lines[note_index + 1:]
    remaining_text = "\n".join(remaining_lines)

    return note_count, remaining_text


def extract_titles(text):
    """
    ä»å¤šè¡Œæ–‡æœ¬ä¸­æå–æ ‡é¢˜

    å‚æ•°:
    text (str): å¤šè¡Œæ–‡æœ¬

    è¿”å›:
    tuple: (æ ‡é¢˜åˆ—è¡¨, å‰©ä½™æ–‡æœ¬)
    """
    lines = text.splitlines()

    # 1. å»é™¤æœ€å‰é¢çš„æ‰€æœ‰ç©ºç™½è¡Œ
    start_index = 0
    for i, line in enumerate(lines):
        if line.strip():  # æ‰¾åˆ°ç¬¬ä¸€ä¸ªéç©ºè¡Œ
            start_index = i
            break
    else:
        # å¦‚æœæ‰€æœ‰è¡Œéƒ½æ˜¯ç©ºç™½è¡Œï¼Œè¿”å›ç©ºç»“æœ
        return [], text

    # ä¿ç•™ä»ç¬¬ä¸€ä¸ªéç©ºè¡Œå¼€å§‹çš„æ‰€æœ‰è¡Œ
    processed_lines = lines[start_index:]

    # 2. åœ¨æœ€å‰é¢åŠ å…¥ä¸¤ä¸ªç©ºç™½è¡Œ
    processed_lines = ['', ''] + processed_lines

    # 3. æå–æ ‡é¢˜è¡Œï¼ˆä¸ä»¥å­—ç¬¦â—†å¼€å¤´ï¼Œä¸”å‰é¢æœ‰ä¸¤ä¸ªç©ºç™½è¡Œçš„è¡Œï¼‰
    titles = []
    remaining_lines = []
    i = 0

    while i < len(processed_lines):
        # æ£€æŸ¥å½“å‰è¡Œæ˜¯å¦æ˜¯æ ‡é¢˜è¡Œ
        if (i + 2 < len(processed_lines) and
                not processed_lines[i].strip() and
                not processed_lines[i + 1].strip() and
                processed_lines[i + 2].strip() and
                not processed_lines[i + 2].startswith('â—†')):

            # æ‰¾åˆ°æ ‡é¢˜è¡Œ
            title_line = processed_lines[i + 2]
            titles.append(title_line.strip())

            # è·³è¿‡è¿™ä¸ªæ ‡é¢˜å—ï¼ˆä¸¤ä¸ªç©ºç™½è¡Œ + æ ‡é¢˜è¡Œï¼‰
            i += 3
        else:
            # ä¸æ˜¯æ ‡é¢˜è¡Œï¼Œä¿ç•™åˆ°å‰©ä½™æ–‡æœ¬
            remaining_lines.append(processed_lines[i])
            i += 1

    # å°†å‰©ä½™è¡Œè½¬æ¢å›å­—ç¬¦ä¸²
    remaining_text = '\n'.join(remaining_lines)

    return titles, remaining_text


def remove_empty_lines(text):
    """
    å»é™¤å­—ç¬¦ä¸²ä¸­çš„æ‰€æœ‰ç©ºç™½è¡Œ

    å‚æ•°:
    text (str): å¤šè¡Œæ–‡æœ¬

    è¿”å›:
    str: å»é™¤æ‰€æœ‰ç©ºç™½è¡Œåçš„æ–‡æœ¬
    """
    lines = text.splitlines()

    # è¿‡æ»¤æ‰æ‰€æœ‰ç©ºç™½è¡Œ
    non_empty_lines = [line for line in lines if line.strip()]

    # é‡æ–°ç»„åˆæˆå­—ç¬¦ä¸²
    return '\n'.join(non_empty_lines)


def split_notes_preserve_format(text, symbol='â—†'):
    """
    æŒ‰ç…§æŒ‡å®šç¬¦å·åˆ†å‰²å­—ç¬¦ä¸²ï¼ˆä¿ç•™æ ¼å¼ç‰ˆæœ¬ï¼‰
    æ¯ä¸ªç¬”è®°åŒ…å«å…¶åŸå§‹æ ¼å¼ï¼ŒåŒ…æ‹¬æ¢è¡Œç¬¦

    å‚æ•°:
    text (str): å¤šè¡Œæ–‡æœ¬
    symbol (str): åˆ†å‰²ç¬¦å·ï¼Œé»˜è®¤ä¸º'â—†'

    è¿”å›:
    list: åˆ†å‰²åçš„ç¬”è®°åˆ—è¡¨
    """
    if not text.strip():
        return []

    # ä½¿ç”¨ç¬¦å·è¿›è¡Œåˆ†å‰²ï¼Œä½†ä¿ç•™æ¢è¡Œç¬¦
    parts = text.split(symbol)

    # å¤„ç†ç¬¬ä¸€ä¸ªéƒ¨åˆ†
    notes = []
    if parts and parts[0].strip():
        # å¦‚æœç¬¬ä¸€ä¸ªéƒ¨åˆ†æœ‰å†…å®¹ï¼Œä¸”ä¸æ˜¯ä»¥ç¬¦å·å¼€å¤´ï¼Œå¯ä»¥å•ç‹¬å¤„ç†æˆ–å¿½ç•¥
        pass

    # ä¸ºå‰©ä½™éƒ¨åˆ†æ·»åŠ ç¬¦å·
    for i, part in enumerate(parts[1:], 1):
        if part.strip():  # åªå¤„ç†éç©ºéƒ¨åˆ†
            note = symbol + part
            notes.append(note)

    return notes


# æ–°å¢å‡½æ•°ï¼šè§£æå•æ¡ç¬”è®°
def parse_single_note(note: str) -> Dict:
    """
    è§£æå•æ¡ç¬”è®°çš„å†…å®¹å’Œç±»å‹

    å‚æ•°:
        note: å•æ¡ç¬”è®°å­—ç¬¦ä¸²

    è¿”å›:
        dict: åŒ…å«ç¬”è®°ä¿¡æ¯çš„å­—å…¸
    """
    note_info = {
        'type': 'unknown',
        'content': '',
        'original_text': '',
        'thought': '',
        'date': '',
        'tags': []
    }

    lines = note.strip().split('\n')

    # æ£€æŸ¥ç¬”è®°ç±»å‹
    if note.startswith('â—† '):
        # å½¢å¼1: åªæœ‰åˆ’çº¿å†…å®¹
        if 'å‘è¡¨æƒ³æ³•' not in note:
            note_info['type'] = 'highlight'
            note_info['content'] = note.replace('â—† ', '').strip()
        # å½¢å¼2: æœ‰æƒ³æ³•å’ŒåŸæ–‡
        else:
            note_info['type'] = 'thought'
            # æå–æ—¥æœŸ
            date_match = re.search(r'â—† (\d{4}/\d{2}/\d{2})å‘è¡¨æƒ³æ³•', note)
            if date_match:
                note_info['date'] = date_match.group(1)

            # åˆ†ç¦»æƒ³æ³•å’ŒåŸæ–‡
            thought_parts = note.split('åŸæ–‡ï¼š')
            if len(thought_parts) == 2:
                # æå–æƒ³æ³•éƒ¨åˆ†ï¼ˆå»æ‰ç¬¬ä¸€è¡Œçš„æ—¥æœŸä¿¡æ¯ï¼‰
                thought_lines = thought_parts[0].split('\n')[1:]  # è·³è¿‡ç¬¬ä¸€è¡Œ
                note_info['thought'] = '\n'.join([line.strip() for line in thought_lines if line.strip()])
                note_info['original_text'] = thought_parts[1].strip()

    # æ£€æµ‹æ ‡ç­¾
    tag_patterns = {
        'Q': r'^Q\s+(.+)',
        'A': r'^A\s+(.+)',
        'C': r'^C\s+(.+)',
        'G': r'^G\s+(.+)',
        'TODO': r'^TODO\s+(.+)',
        'TODO-Q': r'^TODO-Q\s+(.+)'
    }

    for tag, pattern in tag_patterns.items():
        if re.search(pattern, note_info.get('thought', ''), re.MULTILINE) or \
                re.search(pattern, note_info.get('content', ''), re.MULTILINE):
            note_info['tags'].append(tag)

    return note_info


# æ–°å¢å‡½æ•°ï¼šæå–æ‰€æœ‰æ¦‚å¿µ
def extract_concepts(notes: List[Dict]) -> Dict[str, str]:
    """
    ä»ç¬”è®°ä¸­æå–æ‰€æœ‰æ¦‚å¿µåŠå…¶è§£é‡Š

    å‚æ•°:
        notes: ç¬”è®°åˆ—è¡¨

    è¿”å›:
        dict: æ¦‚å¿µåˆ°è§£é‡Šçš„æ˜ å°„
    """
    concepts = {}
    concept_pattern = r'^C\s+(.+?)(?:\n|$)((?:\n(?!\n).*)*)'

    for note in notes:
        # åœ¨æƒ³æ³•ä¸­æŸ¥æ‰¾æ¦‚å¿µ
        if note['thought']:
            matches = re.findall(concept_pattern, note['thought'], re.MULTILINE)
            for match in matches:
                concept = match[0].strip()
                explanation = match[1].strip() if match[1].strip() else concept
                concepts[concept] = explanation

        # åœ¨å†…å®¹ä¸­æŸ¥æ‰¾æ¦‚å¿µ
        if note['content']:
            matches = re.findall(concept_pattern, note['content'], re.MULTILINE)
            for match in matches:
                concept = match[0].strip()
                explanation = match[1].strip() if match[1].strip() else concept
                concepts[concept] = explanation

    return concepts


# æ–°å¢å‡½æ•°ï¼šç”ŸæˆMarkdownå†…å®¹
def generate_markdown(book_title: str, author_name: str, notes: List[Dict], concepts: Dict[str, str]) -> str:
    """
    ç”Ÿæˆå®Œæ•´çš„Markdownæ–‡æ¡£

    å‚æ•°:
        book_title: ä¹¦å
        author_name: ä½œè€…å
        notes: ç¬”è®°åˆ—è¡¨
        concepts: æ¦‚å¿µå­—å…¸

    è¿”å›:
        str: Markdownæ ¼å¼çš„æ–‡æ¡£å†…å®¹
    """
    # æ–‡æ¡£å¤´éƒ¨
    md_content = f"""# {book_title}

**ä½œè€…**: {author_name}  
**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}  
**ç¬”è®°æ•°é‡**: {len(notes)}

---

## ğŸ“ è¯»ä¹¦ç¬”è®°

"""

    # å¤„ç†æ¯æ¡ç¬”è®°
    footnote_counter = 1
    concept_footnotes = {}
    question_footnotes = {}

    for i, note in enumerate(notes, 1):
        md_content += f"### ç¬”è®° {i}\n\n"

        if note['date']:
            md_content += f"**è®°å½•æ—¶é—´**: {note['date']}\n\n"

        # å¤„ç†åŸæ–‡å†…å®¹
        if note['original_text']:
            md_content += f"**åŸæ–‡**: {note['original_text']}\n\n"

        # å¤„ç†æƒ³æ³•å†…å®¹
        if note['thought']:
            thought_content = note['thought']

            # å¤„ç†Q/Aå¯¹
            qa_pattern = r'Q\s+(.+?)\nA\s+(.+)'
            qa_matches = re.findall(qa_pattern, thought_content, re.DOTALL)
            for question, answer in qa_matches:
                question_footnotes[question.strip()] = answer.strip()
                thought_content = thought_content.replace(
                    f"Q {question}\nA {answer}",
                    f"<span title='{answer.strip()}'>Q: {question.strip()}[^{footnote_counter}]</span>"
                )
                footnote_counter += 1

            # å¤„ç†æ¦‚å¿µ
            c_pattern = r'C\s+(.+?)(?:\n|$)'
            c_matches = re.findall(c_pattern, thought_content)
            for concept in c_matches:
                concept = concept.strip()
                if concept in concepts:
                    concept_footnotes[concept] = concepts[concept]
                    thought_content = re.sub(
                        f'C\\s+{re.escape(concept)}',
                        f"<span title='{concepts[concept]}'>C: {concept}[^{footnote_counter}]</span>",
                        thought_content
                    )
                    footnote_counter += 1

            # å¤„ç†TODO
            thought_content = re.sub(r'TODO\s+(.+)', r'- [ ] \1', thought_content)
            thought_content = re.sub(r'TODO-Q\s+(.+)', r'- [ ] Q: \1', thought_content)

            # å¤„ç†Gæ ‡è®°
            thought_content = re.sub(r'G\s+(.+)', r'ğŸŒŸ \1', thought_content)

            md_content += f"**æƒ³æ³•**:\n{thought_content}\n\n"

        elif note['content']:
            content = note['content']
            # å¯¹çº¯å†…å®¹ä¹Ÿè¿›è¡Œæ ‡ç­¾å¤„ç†
            content = re.sub(r'TODO\s+(.+)', r'- [ ] \1', content)
            content = re.sub(r'G\s+(.+)', r'ğŸŒŸ \1', content)
            md_content += f"{content}\n\n"

        md_content += "---\n\n"

    # æ·»åŠ è„šæ³¨
    if question_footnotes or concept_footnotes:
        md_content += "## ğŸ“Œ æ³¨é‡Š\n\n"

        counter = 1
        for question, answer in question_footnotes.items():
            md_content += f"[^{counter}]: **Q**: {question}\n    **A**: {answer}\n\n"
            counter += 1

        for concept, explanation in concept_footnotes.items():
            md_content += f"[^{counter}]: **æ¦‚å¿µ**: {concept}\n    **è§£é‡Š**: {explanation}\n\n"
            counter += 1

    # æ·»åŠ æœ¯è¯­è¡¨
    if concepts:
        md_content += "## ğŸ“š æœ¯è¯­è¡¨\n\n"
        for concept, explanation in sorted(concepts.items()):
            md_content += f"### {concept}\n{explanation}\n\n"

    return md_content


# æ–°å¢å‡½æ•°ï¼šå¤„ç†ä¸Šä¼ çš„æ–‡æœ¬
def process_wechat_notes(text: str) -> Tuple[str, str, str]:
    """
    å¤„ç†å¾®ä¿¡è¯»ä¹¦ç¬”è®°æ–‡æœ¬å¹¶ç”ŸæˆMarkdown

    å‚æ•°:
        text: åŸå§‹æ–‡æœ¬

    è¿”å›:
        tuple: (markdownå†…å®¹, æ–‡ä»¶å, ä¹¦ç±ä¿¡æ¯)
    """
    try:
        # ä½¿ç”¨ä½ æä¾›çš„å‡½æ•°å¤„ç†æ–‡æœ¬
        remaining_text = remove_suffix(text)
        book_title, remaining_text = extract_book_title(remaining_text)
        author_name, remaining_text = extract_author_name(remaining_text)
        note_num, remaining_text = extract_note_count(remaining_text)
        titles, remaining_text = extract_titles(remaining_text)
        remaining_text = remove_empty_lines(remaining_text)
        notes_list = split_notes_preserve_format(remaining_text)

        # è§£ææ¯æ¡ç¬”è®°
        parsed_notes = [parse_single_note(note) for note in notes_list]

        # æå–æ¦‚å¿µ
        concepts = extract_concepts(parsed_notes)

        # ç”ŸæˆMarkdown
        markdown_content = generate_markdown(book_title, author_name, parsed_notes, concepts)

        # ç”Ÿæˆæ–‡ä»¶å
        filename = f"{book_title}_{author_name}_è¯»ä¹¦ç¬”è®°.md".replace(' ', '_').replace('/', '_')

        book_info = f"ã€Š{book_title}ã€‹ - {author_name} - {note_num}"

        return markdown_content, filename, book_info

    except Exception as e:
        st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        return "", "", ""


# Streamlitç•Œé¢
def main():
    """ä¸»å‡½æ•°ï¼šæ„å»ºStreamlitç•Œé¢"""
    st.set_page_config(
        page_title="å¾®ä¿¡è¯»ä¹¦ç¬”è®°æ•´ç†å·¥å…·",
        page_icon="ğŸ“š",
        layout="wide"
    )

    # é¡µé¢æ ‡é¢˜å’Œè¯´æ˜
    st.title("ğŸ“š å¾®ä¿¡è¯»ä¹¦ç¬”è®°æ•´ç†å·¥å…·")
    st.markdown("""
    è¿™ä¸ªå·¥å…·å¯ä»¥å¸®åŠ©ä½ æ•´ç†å¾®ä¿¡è¯»ä¹¦å¯¼å‡ºçš„ç¬”è®°ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºæ ¼å¼ä¼˜ç¾çš„Markdownæ–‡æ¡£ã€‚

    ### ä½¿ç”¨æ–¹æ³•ï¼š
    1. åœ¨å¾®ä¿¡è¯»ä¹¦ä¸­å¯¼å‡ºç¬”è®°åˆ°å‰ªè´´æ¿
    2. å°†å†…å®¹ç²˜è´´åˆ°ä¸‹æ–¹çš„æ–‡æœ¬åŒºåŸŸ
    3. ç‚¹å‡»"ç”ŸæˆMarkdownæ–‡æ¡£"æŒ‰é’®
    4. ä¸‹è½½ç”Ÿæˆçš„æ–‡æ¡£

    ### æ”¯æŒçš„æ ‡ç­¾ï¼š
    - **Q/A**: é—®é¢˜å’Œç­”æ¡ˆ
    - **C**: æ¦‚å¿µå’Œæœ¯è¯­  
    - **G**: å¥½çš„å¥å­æˆ–æƒ³æ³•
    - **TODO**: å¾…åŠäº‹é¡¹
    - **TODO-Q**: æœªè§£å†³çš„é—®é¢˜
    """)

    # æ–‡æœ¬è¾“å…¥åŒºåŸŸ
    st.subheader("ğŸ“ ç²˜è´´å¾®ä¿¡è¯»ä¹¦ç¬”è®°")
    input_text = st.text_area(
        "è¯·å°†å¾®ä¿¡è¯»ä¹¦å¯¼å‡ºçš„ç¬”è®°å†…å®¹ç²˜è´´åˆ°è¿™é‡Œï¼š",
        height=300,
        placeholder="ç²˜è´´ä½ çš„å¾®ä¿¡è¯»ä¹¦ç¬”è®°å†…å®¹åˆ°è¿™é‡Œ..."
    )

    # å¤„ç†æŒ‰é’®
    if st.button("ğŸš€ ç”ŸæˆMarkdownæ–‡æ¡£", type="primary"):
        if not input_text.strip():
            st.warning("è¯·å…ˆç²˜è´´å¾®ä¿¡è¯»ä¹¦ç¬”è®°å†…å®¹ï¼")
            return

        with st.spinner("æ­£åœ¨å¤„ç†ç¬”è®°ï¼Œè¯·ç¨å€™..."):
            markdown_content, filename, book_info = process_wechat_notes(input_text)

            if markdown_content:
                st.success(f"âœ… æˆåŠŸå¤„ç† {book_info}")

                # æ˜¾ç¤ºé¢„è§ˆ
                st.subheader("ğŸ“– æ–‡æ¡£é¢„è§ˆ")
                with st.expander("ç‚¹å‡»æŸ¥çœ‹Markdowné¢„è§ˆ", expanded=True):
                    st.markdown(markdown_content)

                # ä¸‹è½½æŒ‰é’®
                st.subheader("ğŸ“¥ ä¸‹è½½æ–‡æ¡£")
                st.download_button(
                    label="ä¸‹è½½Markdownæ–‡æ¡£",
                    data=markdown_content,
                    file_name=filename,
                    mime="text/markdown",
                    icon="ğŸ“„"
                )

                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                st.subheader("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯")
                col1, col2, col3 = st.columns(3)

                with col1:
                    st.metric("ç¬”è®°æ•°é‡", len(markdown_content.split("### ç¬”è®°")) - 1)
                with col2:
                    concept_count = len(re.findall(r'C:\s+', markdown_content))
                    st.metric("æ¦‚å¿µæ•°é‡", concept_count)
                with col3:
                    question_count = len(re.findall(r'Q:\s+', markdown_content))
                    st.metric("é—®é¢˜æ•°é‡", question_count)


if __name__ == "__main__":
    main()