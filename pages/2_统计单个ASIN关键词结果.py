import streamlit as st
import pandas as pd
import re
import plotly.express as px
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from shared.sidebar import create_common_sidebar # <-- 1. å¯¼å…¥å‡½æ•°
create_common_sidebar() # <-- 2. è°ƒç”¨å‡½æ•°ï¼Œç¡®ä¿æ¯ä¸ªé¡µé¢éƒ½æœ‰ä¾§è¾¹æ 

# --- 1. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---

def parse_filename(filename):
    """
    ä»Žæ–‡ä»¶åä¸­è§£æžå‡ºå›½å®¶ã€ASINã€å…³é”®è¯æ•°é‡å’Œæ—¥æœŸã€‚
    æ–‡ä»¶åæ ¼å¼: ReverseASIN-US-B01N9KSITZ(1584)-20251012.xlsx
    """
    match = re.search(r'ReverseASIN-(.+)-(.+)\((\d+)\)-(\d+)', filename)
    if match:
        country, asin, keyword_count, date = match.groups()
        # æ ¼å¼åŒ–æ—¥æœŸ
        formatted_date = f"{date[:4]}-{date[4:6]}-{date[6:]}"
        return country, asin, int(keyword_count), formatted_date
    return None, None, None, None

def load_data(uploaded_file):
    """
    åŠ è½½ä¸Šä¼ çš„Excelæ–‡ä»¶ï¼Œå¹¶è¯»å–ç¬¬ä¸€ä¸ªsheetçš„æ•°æ®ã€‚
    """
    if uploaded_file is not None:
        try:
            # è¯»å–ç¬¬ä¸€ä¸ªsheet
            df = pd.read_excel(uploaded_file, engine='openpyxl', sheet_name=0)
            return df
        except Exception as e:
            st.error(f"åŠ è½½æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return None
    return None

def display_metrics(df):
    """
    è®¡ç®—å¹¶å±•ç¤ºæ ¸å¿ƒä¸šåŠ¡æŒ‡æ ‡ã€‚
    """
    st.header("æ ¸å¿ƒæŒ‡æ ‡æ¦‚è§ˆ")

    # åœ¨è®¡ç®—å‰ï¼Œå¼ºåˆ¶å°†ç›¸å…³åˆ—è½¬æ¢ä¸ºæ•°å­—æ ¼å¼ã€‚
    df['é¢„ä¼°å‘¨æ›å…‰é‡'] = pd.to_numeric(df['é¢„ä¼°å‘¨æ›å…‰é‡'], errors='coerce')
    df['éœ€ä¾›æ¯”'] = pd.to_numeric(df['éœ€ä¾›æ¯”'], errors='coerce')
    df['è´­ä¹°é‡'] = pd.to_numeric(df['è´­ä¹°é‡'], errors='coerce')
    # 'è´­ä¹°çŽ‡' å¯èƒ½åŒ…å«ç™¾åˆ†å·ï¼Œéœ€è¦å…ˆç§»é™¤
    if df['è´­ä¹°çŽ‡'].dtype == 'object':
         df['è´­ä¹°çŽ‡'] = pd.to_numeric(df['è´­ä¹°çŽ‡'].str.replace('%', '', regex=False), errors='coerce') / 100
    else:
        df['è´­ä¹°çŽ‡'] = pd.to_numeric(df['è´­ä¹°çŽ‡'], errors='coerce')

    # è®¡ç®—æŒ‡æ ‡
    total_weekly_impressions = df['é¢„ä¼°å‘¨æ›å…‰é‡'].sum()
    average_supply_demand_ratio = df['éœ€ä¾›æ¯”'].mean()
    total_purchase = df['è´­ä¹°é‡'].sum()
    average_purchase_rate = df['è´­ä¹°çŽ‡'].mean()

    # åˆ›å»ºåˆ—æ¥å¹¶æŽ’æ˜¾ç¤ºæŒ‡æ ‡
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("é¢„ä¼°å‘¨æ›å…‰æ€»é‡", f"{int(total_weekly_impressions):,}")
    col2.metric("å¹³å‡éœ€ä¾›æ¯”", f"{average_supply_demand_ratio:.2f}")
    col3.metric("å…³é”®è¯æ€»è´­ä¹°é‡", f"{int(total_purchase):,}")
    col4.metric("å¹³å‡è´­ä¹°çŽ‡", f"{average_purchase_rate:.2%}")


def plot_top_keywords_by_traffic(df):
    """
    ç»˜åˆ¶æµé‡å æ¯”æœ€é«˜çš„TOP 10å…³é”®è¯æ¡å½¢å›¾ã€‚
    """
    st.subheader("æµé‡å æ¯” TOP 10 å…³é”®è¯")

    # åœ¨ç»˜å›¾å‰ï¼Œç¡®ä¿'æµé‡å æ¯”'åˆ—æ˜¯æ•°å­—ç±»åž‹
    if df['æµé‡å æ¯”'].dtype == 'object':
        df['æµé‡å æ¯”'] = pd.to_numeric(df['æµé‡å æ¯”'].str.replace('%', '', regex=False), errors='coerce') / 100
    else:
        df['æµé‡å æ¯”'] = pd.to_numeric(df['æµé‡å æ¯”'], errors='coerce')

    # æŒ‰â€œæµé‡å æ¯”â€é™åºæŽ’åºå¹¶é€‰å–å‰10
    top_10_keywords = df.sort_values(by='æµé‡å æ¯”', ascending=False).head(10)

    # åˆ›å»ºæ¡å½¢å›¾
    fig = px.bar(
        top_10_keywords,
        x='æµé‡å æ¯”',
        y='æµé‡è¯',
        orientation='h',
        title='æµé‡å æ¯”æœ€é«˜çš„10ä¸ªå…³é”®è¯',
        labels={'æµé‡å æ¯”': 'æµé‡å æ¯”', 'æµé‡è¯': 'å…³é”®è¯'},
        text='æµé‡å æ¯”'
    )
    # æ›´æ–°å›¾è¡¨å¸ƒå±€
    fig.update_layout(
        yaxis={'categoryorder':'total ascending'},
        xaxis_title="æµé‡å æ¯”",
        yaxis_title="å…³é”®è¯",
        xaxis_tickformat=".2%"
    )
    fig.update_traces(texttemplate='%{x:.2%}', textposition='outside')
    st.plotly_chart(fig, use_container_width=True)


def plot_keyword_type_distribution(df):
    """
    ç»˜åˆ¶å…³é”®è¯ç±»åž‹çš„åˆ†å¸ƒé¥¼å›¾ã€‚
    """
    st.subheader("å…³é”®è¯ç±»åž‹åˆ†å¸ƒ")
    type_counts = df['å…³é”®è¯ç±»åž‹'].value_counts().reset_index()
    type_counts.columns = ['å…³é”®è¯ç±»åž‹', 'æ•°é‡']

    fig = px.pie(
        type_counts,
        names='å…³é”®è¯ç±»åž‹',
        values='æ•°é‡',
        title='å„ç±»å…³é”®è¯æ•°é‡å æ¯”'
    )
    st.plotly_chart(fig, use_container_width=True)

def generate_word_cloud(df):
    """
    æ ¹æ®â€œæµé‡è¯â€ç”Ÿæˆå¹¶å±•ç¤ºè¯äº‘ã€‚
    """
    st.subheader("å…³é”®è¯è¯äº‘")
    text = " ".join(keyword for keyword in df['æµé‡è¯'].dropna().astype(str))

    if not text:
        st.warning("å…³é”®è¯æ•°æ®ä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆè¯äº‘ã€‚")
        return

    try:
        wordcloud = WordCloud(
            width=800,
            height=400,
            background_color='white',
            collocations=False
        ).generate(text)

        fig, ax = plt.subplots()
        ax.imshow(wordcloud, interpolation='bilinear')
        ax.axis('off')
        st.pyplot(fig)
    except Exception as e:
        st.error(f"ç”Ÿæˆè¯äº‘æ—¶å‡ºé”™: {e}")


# --- 2. Streamlit é¡µé¢ä¸»å‡½æ•° (æ·»åŠ äº†åŠ è½½çŠ¶æ€) ---

def main():
    """
    Streamlitåº”ç”¨çš„ä¸»å‡½æ•°ï¼Œå…·æœ‰æ¸…æ™°çš„æ•°æ®åŠ è½½å’Œæ¸…é™¤é€»è¾‘ã€‚
    """
    st.set_page_config(page_title="ASINåæŸ¥å…³é”®è¯åˆ†æžé¢æ¿", layout="wide")

    st.title("ðŸ“Š ASINåæŸ¥å…³é”®è¯åˆ†æžé¢æ¿")

    # --- æ ¸å¿ƒäº¤äº’é€»è¾‘ ---
    # æ ¹æ® session_state ä¸­æ˜¯å¦å­˜åœ¨æ•°æ®ï¼Œå†³å®šæ˜¾ç¤ºâ€œåˆ†æžæŠ¥å‘Šâ€è¿˜æ˜¯â€œæ–‡ä»¶ä¸Šä¼ â€ç•Œé¢
    if 'processed_data' in st.session_state:
        # --- çŠ¶æ€ä¸€ï¼šå·²åŠ è½½æ•°æ®ï¼Œæ˜¾ç¤ºåˆ†æžæŠ¥å‘Š ---
        df = st.session_state['processed_data']
        info = st.session_state['file_info']

        header_container = st.container()
        with header_container:
            col1, col2 = st.columns([0.85, 0.15]) # è°ƒæ•´å®½åº¦æ¯”ä¾‹ä»¥é€‚åº”æŒ‰é’®æ–‡å­—
            with col1:
                if info['asin']:
                    st.success(f"å½“å‰åˆ†æžçš„æ–‡ä»¶: **{info['name']}** | å›½å®¶: **{info['country']}**, ASIN: **{info['asin']}**, å…³é”®è¯æ€»æ•°: **{info['keyword_count']}**")
                else:
                    st.warning("æ— æ³•ä»Žæ–‡ä»¶åä¸­è§£æžä¿¡æ¯ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶åæ ¼å¼ã€‚")
            with col2:
                if st.button("æ¸…é™¤å¹¶åˆ†æžæ–°æ–‡ä»¶", use_container_width=True):
                    del st.session_state['processed_data']
                    del st.session_state['file_info']
                    st.rerun()

        # --- æ˜¾ç¤ºæ‰€æœ‰å›¾è¡¨å’Œæ•°æ® ---
        display_metrics(df.copy())
        st.markdown("---")
        col1, col2 = st.columns(2)
        with col1:
            plot_top_keywords_by_traffic(df.copy())
        with col2:
            plot_keyword_type_distribution(df.copy())
        generate_word_cloud(df.copy())
        st.markdown("---")
        st.subheader("è¯¦ç»†æ•°æ®è¡¨")
        st.dataframe(df)

    else:
        # --- çŠ¶æ€äºŒï¼šåˆå§‹çŠ¶æ€ï¼Œæ˜¾ç¤ºæ–‡ä»¶ä¸Šä¼ ç•Œé¢ ---
        st.header("ä¸Šä¼ æ•°æ®æ–‡ä»¶")
        uploaded_file = st.file_uploader(
            "è¯·åœ¨æ­¤å¤„ä¸Šä¼ æ‚¨çš„ASINåæŸ¥å…³é”®è¯Excelæ–‡ä»¶ä»¥å¼€å§‹åˆ†æž",
            type=["xlsx"],
            key="file_uploader"
        )

        if uploaded_file is not None:
            # âœ¨ æ–°å¢žï¼šä½¿ç”¨ st.spinner æ˜¾ç¤ºåŠ è½½çŠ¶æ€
            with st.spinner('æ­£åœ¨åŠ è½½å’Œå¤„ç†æ–‡ä»¶ï¼Œè¯·ç¨å€™...'):
                df = load_data(uploaded_file)
                if df is not None:
                    country, asin, keyword_count, date = parse_filename(uploaded_file.name)
                    st.session_state['processed_data'] = df
                    st.session_state['file_info'] = {
                        'name': uploaded_file.name,
                        'country': country,
                        'asin': asin,
                        'keyword_count': keyword_count,
                        'date': date
                    }
                    # æ•°æ®å¤„ç†å®ŒæˆåŽï¼Œé‡æ–°è¿è¡Œè„šæœ¬ä»¥è¿›å…¥â€œåˆ†æžæŠ¥å‘Šâ€çŠ¶æ€
                    st.rerun()
        else:
            st.info("ðŸ‘‹ æ¬¢è¿Žä½¿ç”¨ï¼è¯·ä¸Šä¼ æ–‡ä»¶ä»¥å¼€å§‹åˆ†æžã€‚")


# --- 3. åº”ç”¨å¯åŠ¨ ---

if __name__ == "__main__":
    main()
