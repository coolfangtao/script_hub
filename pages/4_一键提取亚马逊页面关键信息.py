import streamlit as st
from bs4 import BeautifulSoup
import re
import pandas as pd  # å¯¼å…¥ pandas ç”¨äºè¡¨æ ¼


# --- æ‚¨æä¾›çš„åŸå§‹è§£æå‡½æ•° ---
# (ä¸ºäº†ä¿æŒä»£ç æ•´æ´ï¼Œè¿™é‡Œçœç•¥äº†å‡½æ•°çš„å†…éƒ¨å®ç°ï¼Œä½†å®ƒä»¬ä¸æ‚¨æä¾›çš„ä¸€è‡´)

def extract_all_product_info(html_content):
    """
    ä»ç½‘é¡µæºä»£ç ä¸­æå–å•†å“çš„æ‰€æœ‰å…³é”®ä¿¡æ¯
    """
    soup = BeautifulSoup(html_content, 'html.parser')
    results = {}

    # 1. æå–å•†å“ç‰¹æ€§åˆ—è¡¨
    features = extract_features(soup)
    results['features'] = features

    # 2. æå–å•†å“æ ‡é¢˜
    title = extract_title(soup)
    results['title'] = title

    # 3. æå–ä»·æ ¼ä¿¡æ¯
    price = extract_price(soup)
    results['price'] = price

    # 4. æå–è¯„åˆ†ä¿¡æ¯
    rating_info = extract_rating(soup)
    results['rating'] = rating_info

    # 5. æå–æ‰€æœ‰ç”¨æˆ·è¯„è®º (æ–°å¢)
    reviews = extract_reviews(soup)
    results['reviews'] = reviews

    return results


def extract_features(soup):
    """
    æå–å•†å“ç‰¹æ€§åˆ—è¡¨
    """
    features = []
    feature_section = soup.find('div', id='feature-bullets')

    if feature_section:
        list_items = feature_section.find_all('li', class_='a-spacing-mini')
        for item in list_items:
            span = item.find('span', class_='a-list-item')
            if span:
                text = span.get_text(strip=True)
                features.append(text)

    return features


def extract_title(soup):
    """
    æå–å•†å“æ ‡é¢˜
    """
    title_span = soup.find('span', id='productTitle')
    if title_span:
        return title_span.get_text(strip=True)
    return None


def extract_price(soup):
    """
    æå–ä»·æ ¼ä¿¡æ¯
    """
    # æ–¹æ³•1ï¼šé€šè¿‡ç‰¹å®šclasså®šä½
    # å°è¯•æŸ¥æ‰¾ 'a-price' ç»“æ„
    price_span = soup.find('span', class_='a-price')
    if price_span:
        price_text = price_span.find('span', class_='a-offscreen')
        if price_text:
            return price_text.get_text(strip=True).replace('$', '').replace('ï¿¥', '')  # ç§»é™¤è´§å¸ç¬¦å·

    # æ–¹æ³•2ï¼šç»„åˆ 'a-price-symbol', 'a-price-whole', 'a-price-fraction'
    price_symbol = soup.find('span', class_='a-price-symbol')
    if price_symbol:
        whole_price = soup.find('span', class_='a-price-whole')
        fraction_price = soup.find('span', class_='a-price-fraction')

        if whole_price and fraction_price:
            whole_text = whole_price.get_text(strip=True).replace('.', '').replace(',', '')
            fraction_text = fraction_price.get_text(strip=True)
            return f"{whole_text}.{fraction_text}"

    # æ–¹æ³•3ï¼šå¤‡é€‰æ–¹æ¡ˆï¼Œæœç´¢ä»·æ ¼æ¨¡å¼ (ä½œä¸ºæœ€åçš„å°è¯•)
    price_pattern = r'[\$ï¿¥]\d+[\.,]\d{2}'  # åŒ¹é… $19.99 æˆ– ï¿¥19,99
    text_content = soup.get_text()
    price_matches = re.findall(price_pattern, text_content)
    if price_matches:
        # æ¸…ç†æ‰¾åˆ°çš„ç¬¬ä¸€ä¸ªåŒ¹é…é¡¹
        return price_matches[0].replace('$', '').replace('ï¿¥', '').replace(',', '.')

    return None


def extract_rating(soup):
    """
    æå–è¯„åˆ†ä¿¡æ¯
    """
    rating_info = {}

    # æå–è¯„åˆ†æè¿°ï¼ˆä¾‹å¦‚ "4.3 out of 5 stars"ï¼‰
    rating_alt = soup.find('span', class_='a-icon-alt')
    if rating_alt:
        rating_text = rating_alt.get_text(strip=True)
        rating_info['full_text'] = rating_text
        # å°è¯•ä»ä¸­æå–åˆ†æ•°
        score_match = re.search(r'(\d+\.?\d*)\s*out\s*of\s*5', rating_text)
        if score_match:
            rating_info['score'] = score_match.group(1)

    # å¦‚æœä¸Šè¿°æ–¹æ³•å¤±è´¥ï¼Œå°è¯•æŸ¥æ‰¾è¯„åˆ†æ•°å­—ï¼ˆä¾‹å¦‚ "4.3"ï¼‰
    if 'score' not in rating_info:
        rating_span = soup.find('span', class_='a-size-base', string=re.compile(r'^\d+\.\d$'))
        if rating_span:
            rating_info['score'] = rating_span.get_text(strip=True)

    # æå–è¯„ä»·æ•°é‡
    review_count = soup.find('span', id='acrCustomerReviewText')
    if review_count:
        rating_info['review_count'] = review_count.get_text(strip=True)

    return rating_info


# --- (æ–°å¢) æå–è¯„è®ºå‡½æ•° ---

def extract_reviews(soup):
    """
    æå–æ‰€æœ‰ç”¨æˆ·è¯„è®ºä¿¡æ¯ (å·²é›†æˆ)
    """
    reviews = []

    # ä½¿ç”¨æ¨¡ç³ŠåŒ¹é…æ‰¾åˆ°æ‰€æœ‰è¯„è®ºå®¹å™¨
    # (å·²å¢å¼ºï¼šæ·»åŠ å¤‡ç”¨é€‰æ‹©å™¨)
    review_containers = soup.find_all('div', id=re.compile(r'(customer_review-|review-)'))

    if not review_containers:
        review_containers = soup.find_all('div', attrs={'data-hook': 'review'})

    for container in review_containers:
        review = {}

        # 1. æå–ç”¨æˆ·å
        profile_name = container.find('span', class_='a-profile-name')
        if profile_name:
            review['username'] = profile_name.get_text(strip=True)

        # 2. æå–è¯„è®ºæ ‡é¢˜/æ¦‚è¦
        review_title = container.find('span', class_='review-title-content')
        if review_title:
            review['title'] = review_title.get_text(strip=True)
        else:
            # å¤‡é€‰æ–¹æ³•ï¼šé€šè¿‡data-hookå±æ€§
            title_element = container.find('span', attrs={'data-hook': 'review-title'})
            if title_element:
                # è·å–æ ‡é¢˜æ–‡æœ¬ï¼Œè·³è¿‡æ˜Ÿçº§éƒ¨åˆ†
                title_text = title_element.get_text(strip=True)
                # ç§»é™¤æ˜Ÿçº§æ–‡æœ¬ï¼Œåªä¿ç•™æ ‡é¢˜
                # (è¿™ä¸ªé€»è¾‘å¯èƒ½ä¸æ€»æ˜¯å‡†ç¡®ï¼Œä½†ä¿ç•™åŸæ ·)
                if 'out of 5 stars' in title_text:
                    # å°è¯•æ›´å‡†ç¡®åœ°åˆ†å‰²
                    parts = re.split(r'\d+\.\d out of 5 stars', title_text)
                    if len(parts) > 1:
                        title_text = parts[1].strip()
                    else:
                        # å¤‡ç”¨æ–¹æ¡ˆ
                        title_text = title_text.split('out of 5 stars')[-1].strip()
                review['title'] = title_text

        # 3. æå–æ˜Ÿçº§è¯„åˆ†
        star_rating_icon = container.find('i', attrs={'data-hook': 'review-star-rating'})
        if star_rating_icon:
            # å°è¯•ä» 'a-icon-alt' ä¸­è·å–
            star_text = star_rating_icon.find('span', class_='a-icon-alt')
            if star_text:
                match = re.search(r'(\d+\.?\d*) out of 5 stars', star_text.get_text())
                if match:
                    review['rating'] = match.group(1)

        # å¤‡é€‰æ–¹æ¡ˆ (æ¥è‡ªæ‚¨çš„ä»£ç )
        if 'rating' not in review:
            star_rating = container.find('i', class_=re.compile(r'a-star-\d'))
            if star_rating:
                # ä»classåä¸­æå–æ˜Ÿçº§æ•°å­—
                class_names = star_rating.get('class', [])
                for class_name in class_names:
                    if class_name.startswith('a-star-'):
                        # æå–æ•°å­—ï¼Œå¦‚ "a-star-4" -> "4"
                        review['rating'] = class_name.split('-')[-1].replace('-', '.')  # å…¼å®¹ a-star-4-5
                        break

        # 4. æå–è¯„è®ºæ—¥æœŸ
        review_date = container.find('span', attrs={'data-hook': 'review-date'})
        if review_date:
            review['date'] = review_date.get_text(strip=True)

        # 5. æå–è¯„è®ºæ­£æ–‡
        review_body = container.find('span', attrs={'data-hook': 'review-body'})
        if review_body:
            # è·å–è¯„è®ºæ–‡æœ¬ï¼ŒåŒ…æ‹¬å¯èƒ½è¢«æŠ˜å çš„å†…å®¹
            review_text = review_body.get_text(strip=True)
            review['content'] = review_text

        # 6. æå–æ˜¯å¦æœ‰Verified Purchase
        verified_badge = container.find('span', attrs={'data-hook': 'avp-badge-linkless'})
        if verified_badge and 'Verified Purchase' in verified_badge.get_text():
            review['verified'] = True
        else:
            # å¤‡é€‰
            verified_badge_alt = container.find('span', class_='a-size-mini', string=re.compile('Verified Purchase'))
            if verified_badge_alt:
                review['verified'] = True
            else:
                review['verified'] = False

        # 7. æå–æœ‰å¸®åŠ©çš„æ•°é‡
        helpful_text = container.find('span', attrs={'data-hook': 'helpful-vote-statement'})
        if helpful_text:
            helpful_count = helpful_text.get_text(strip=True)
            review['helpful_count'] = helpful_count

        if review:  # åªæ·»åŠ æœ‰å†…å®¹çš„è¯„è®º
            reviews.append(review)

    return reviews


# --- (æ–°å¢) Streamlit ç¼“å­˜å‡½æ•° ---
@st.cache_data
def convert_df_to_csv(df):
    """
    å°† DataFrame è½¬æ¢ä¸º CSV æ ¼å¼ (ç”¨äºä¸‹è½½)
    ä½¿ç”¨ utf-8-sig ç¼–ç ç¡®ä¿ Excel æ­£ç¡®æ‰“å¼€
    """
    return df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')


# --- (æ–°å¢) æ ¼å¼åŒ–åŸºæœ¬ä¿¡æ¯ ---
def format_other_info_for_display(results):
    """
    å°†åŸºæœ¬ä¿¡æ¯æ ¼å¼åŒ–ä¸ºå•ä¸ªå­—ç¬¦ä¸²ä»¥ä¾¿å¤åˆ¶
    """
    lines = []

    # æ ‡é¢˜
    if results['title']:
        lines.append(f"å•†å“æ ‡é¢˜: {results['title']}")
    else:
        lines.append("å•†å“æ ‡é¢˜: æœªæ‰¾åˆ°")

    lines.append("-" * 40)

    # ä»·æ ¼
    if results['price']:
        lines.append(f"å•†å“ä»·æ ¼: {results['price']}")
    else:
        lines.append("å•†å“ä»·æ ¼: æœªæ‰¾åˆ°")

    lines.append("-" * 40)

    # è¯„åˆ†
    if results['rating']:
        rating = results['rating']
        lines.append("è¯„åˆ†ä¿¡æ¯:")
        if 'score' in rating:
            lines.append(f"  - è¯„åˆ†: {rating['score']}/5")
        if 'full_text' in rating:
            lines.append(f"  - è¯¦æƒ…: {rating['full_text']}")
        if 'review_count' in rating:
            lines.append(f"  - è¯„ä»·æ•°é‡: {rating['review_count']}")
    else:
        lines.append("è¯„åˆ†ä¿¡æ¯: æœªæ‰¾åˆ°")

    lines.append("-" * 40)

    # ç‰¹æ€§
    if results['features']:
        lines.append("å•†å“ç‰¹æ€§:")
        for i, feature in enumerate(results['features'], 1):
            lines.append(f"  {i}. {feature}")
    else:
        lines.append("å•†å“ç‰¹æ€§: æœªæ‰¾åˆ°")

    return "\n".join(lines)


# --- (æ–°å¢) æ ¼å¼åŒ–è¯„è®ºä¸ºç®€æ´æ–‡æœ¬ ---
def format_reviews_simple_text(reviews):
    """
    å°†è¯„è®ºåˆ—è¡¨æ ¼å¼åŒ–ä¸ºç®€æ´çš„æ–‡æœ¬å­—ç¬¦ä¸²
    """
    lines = []
    if not reviews:
        return "æœªæ‰¾åˆ°è¯„è®ºã€‚"

    for i, review in enumerate(reviews, 1):
        lines.append(f"ã€è¯„è®º {i}ã€‘")
        lines.append(f"ç”¨æˆ·å: {review.get('username', 'N/A')}")
        lines.append(f"è¯„åˆ†: {review.get('rating', '?')}/5")
        lines.append(f"æ—¥æœŸ: {review.get('date', 'N/A')}")
        lines.append(f"æ ‡é¢˜: {review.get('title', 'æ— æ ‡é¢˜')}")
        verified_text = "æ˜¯" if review.get('verified', False) else "å¦"
        lines.append(f"å·²éªŒè¯è´­ä¹°: {verified_text}")
        if review.get('helpful_count'):
            lines.append(f"æœ‰å¸®åŠ©: {review.get('helpful_count')}")
        lines.append(f"å†…å®¹: {review.get('content', 'æ— å†…å®¹')}")
        lines.append("\n" + "-" * 30 + "\n")

    return "\n".join(lines)


# --- ç”¨äºStreamlitçš„æ–°å‡½æ•° ---

def display_streamlit_results(results):
    """
    åœ¨Streamlité¡µé¢ä¸Šæ ¼å¼åŒ–æ˜¾ç¤ºæå–ç»“æœ (å·²ä¿®æ”¹)
    """
    st.header("æå–ç»“æœ")
    st.markdown("---")

    # --- 1. æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯ (æ–‡æœ¬æ¡†) ---
    st.subheader("ğŸ“¦ å•†å“åŸºæœ¬ä¿¡æ¯")
    other_info_text = format_other_info_for_display(results)
    # ä½¿ç”¨ disabled=True ä½¿å…¶åªè¯»ï¼Œä½†ç”¨æˆ·ä»å¯å¤åˆ¶
    st.text_area("åŸºæœ¬ä¿¡æ¯ (å¯å¤åˆ¶):", value=other_info_text, height=300, disabled=True, key="other_info_area")

    st.markdown("\n\n---\n")

    # --- 2. æ˜¾ç¤ºè¯„è®º (è¡¨æ ¼) ---
    st.subheader("ğŸ’¬ ç”¨æˆ·è¯„è®º")
    if results.get('reviews'):
        reviews_list = results['reviews']
        st.write(f"å…±æ‰¾åˆ° {len(reviews_list)} æ¡è¯„è®º")

        try:
            # --- 2a. åˆ›å»º DataFrame ---
            df = pd.DataFrame(reviews_list)

            # è°ƒæ•´åˆ—é¡ºåºä»¥ä¾¿æŸ¥çœ‹
            cols_order = ['username', 'rating', 'date', 'title', 'content', 'verified', 'helpful_count']
            # è¿‡æ»¤æ‰æ•°æ®ä¸­ä¸å­˜åœ¨çš„åˆ— (ä»¥é˜²ä¸‡ä¸€)
            existing_cols = [col for col in cols_order if col in df.columns]
            df_display = df[existing_cols]

            st.dataframe(df_display, use_container_width=True)

            # --- 2b. ä¸‹è½½æŒ‰é’® ---
            csv_data = convert_df_to_csv(df_display)
            st.download_button(
                label="ä¸‹è½½è¯„è®º (CSV æ–‡ä»¶)",
                data=csv_data,
                file_name="amazon_reviews.csv",
                mime="text/csv",
                key="download_csv"
            )

            # --- 2c. ç®€æ´æ–‡æœ¬æ ¼å¼ ---
            st.subheader("ç®€æ´æ–‡æœ¬ç‰ˆè¯„è®º (å¯å¤åˆ¶)")
            simple_reviews_text = format_reviews_simple_text(reviews_list)
            st.text_area("è¯„è®ºæ–‡æœ¬:", value=simple_reviews_text, height=400, disabled=True, key="reviews_text_area")

        except Exception as e:
            st.error(f"å¤„ç†è¯„è®ºè¡¨æ ¼æ—¶å‡ºé”™: {e}")
            st.write("æ— æ³•ç”Ÿæˆè¡¨æ ¼ï¼Œæ˜¾ç¤ºåŸå§‹è¯„è®ºæ•°æ®ï¼š")
            st.json(reviews_list)  # ä½œä¸ºåå¤‡ï¼Œç›´æ¥æ‰“å°JSON

    else:
        st.info("æœªæ‰¾åˆ°ç”¨æˆ·è¯„è®ºã€‚")


# (æ­¤å‡½æ•°å·²è¢«ç§»é™¤ï¼ŒåŠŸèƒ½è¢« format_other_info_for_display å’Œ format_reviews_simple_text æ›¿ä»£)
# def format_results_for_copy(results):
#     ...

# --- Streamlit åº”ç”¨ç¨‹åºç•Œé¢ ---

# è®¾ç½®é¡µé¢æ ‡é¢˜
st.set_page_config(page_title="äºšé©¬é€Šä¿¡æ¯æå–å™¨", page_icon="ğŸ“¦")

st.title("ğŸ“¦ äºšé©¬é€Šå•†å“ä¿¡æ¯æå–å·¥å…·")

st.info("è¯·åœ¨å•†å“é¡µé¢å³é”® â†’ 'æŸ¥çœ‹ç½‘é¡µæºä»£ç ' â†’ å…¨é€‰ (Ctrl+A) â†’ å¤åˆ¶ (Ctrl+C) â†’ ç²˜è´´åˆ°ä¸‹æ–¹æ–‡æœ¬æ¡†ä¸­ã€‚")

# ç”¨äºç²˜è´´HTMLçš„æ–‡æœ¬åŒºåŸŸ
html_content = st.text_area("åœ¨æ­¤å¤„ç²˜è´´ç½‘é¡µæºä»£ç :", height=300, key="html_input", placeholder="å°†HTMLæºä»£ç ç²˜è´´åˆ°è¿™é‡Œ...")

# æå–æŒ‰é’®
if st.button("æå–ä¿¡æ¯", key="extract_button", type="primary"):
    if html_content:
        with st.spinner("æ­£åœ¨è§£æä¸­ï¼Œè¯·ç¨å€™..."):
            try:
                # æå–æ‰€æœ‰ä¿¡æ¯
                results = extract_all_product_info(html_content)

                # åœ¨é¡µé¢ä¸Šæ˜¾ç¤ºç»“æœ (ä½¿ç”¨ä¿®æ”¹åçš„å‡½æ•°)
                display_streamlit_results(results)

                # (æ—§çš„å¤åˆ¶éƒ¨åˆ†å·²ç§»é™¤)

                st.success("æå–å®Œæˆï¼")

            except Exception as e:
                st.error(f"è§£ææ—¶å‘ç”Ÿé”™è¯¯: {e}")
                st.exception(e)
    else:
        st.warning("è­¦å‘Šï¼šæ–‡æœ¬æ¡†ä¸ºç©ºï¼Œè¯·è¾“å…¥ç½‘é¡µæºä»£ç ã€‚")


