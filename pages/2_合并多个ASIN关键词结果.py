import streamlit as st
import pandas as pd
import re
from io import BytesIO
from typing import List, Dict, Tuple, Optional
from shared.sidebar import create_common_sidebar # <-- 1. å¯¼å…¥å‡½æ•°
create_common_sidebar() # <-- 2. è°ƒç”¨å‡½æ•°ï¼Œç¡®ä¿æ¯ä¸ªé¡µé¢éƒ½æœ‰ä¾§è¾¹æ 


# --- æ ¸å¿ƒåŠŸèƒ½å‡½æ•° (Core Logic Functions) ---

def parse_filename(filename: str) -> Optional[Dict[str, str]]:
    """
    ä»æ ‡å‡†æ–‡ä»¶åä¸­è§£æå‡ºASINç­‰ä¿¡æ¯ã€‚
    æ–‡ä»¶åæ ¼å¼: ReverseASIN-US-B01N9KSITZ(1584)-20251012.xlsx

    Args:
        filename (str): ä¸Šä¼ æ–‡ä»¶çš„åç§°ã€‚

    Returns:
        Optional[Dict[str, str]]: åŒ…å«'country'å’Œ'asin'çš„å­—å…¸ï¼Œå¦‚æœæ ¼å¼ä¸åŒ¹é…åˆ™è¿”å›Noneã€‚
    """
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ–‡ä»¶åä¸­çš„å…³é”®ä¿¡æ¯
    # - Group 1: (.*?) -> å›½å®¶ä»£ç  (e.g., US)
    # - Group 2: ([A-Z0-9]{10}) -> 10ä½å­—æ¯å’Œæ•°å­—ç»„æˆçš„ASIN (e.g., B01N9KSITZ)
    pattern = re.compile(r'ReverseASIN-(.*?)-([A-Z0-9]{10})\(.*\)-\d+')
    match = pattern.match(filename)

    if match:
        return {
            'country': match.group(1),
            'asin': match.group(2)
        }
    return None

def process_uploaded_file(uploaded_file) -> Optional[Tuple[str, pd.DataFrame, pd.DataFrame]]:
    """
    å¤„ç†å•ä¸ªä¸Šä¼ çš„Excelæ–‡ä»¶ã€‚
    1. è¯»å–ç¬¬ä¸€ä¸ªsheetã€‚
    2. è§£ææ–‡ä»¶åè·å–ASINã€‚
    3. åˆ›å»ºä¸€ä¸ªæ–°DataFrameï¼Œå¹¶åœ¨ç¬¬ä¸€åˆ—æ·»åŠ ASINä¿¡æ¯ã€‚

    Args:
        uploaded_file: Streamlitä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡ã€‚

    Returns:
        Optional[Tuple[str, pd.DataFrame, pd.DataFrame]]:
        ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…å«:
        - åŸå§‹sheetçš„åç§°ã€‚
        - åŸå§‹sheetçš„å®Œæ•´DataFrame (ç”¨äºå•ç‹¬å­˜æ”¾)ã€‚
        - æ·»åŠ äº†ASINåˆ—çš„DataFrame (ç”¨äºæ€»è¡¨åˆå¹¶)ã€‚
        å¦‚æœæ–‡ä»¶å¤„ç†å¤±è´¥æˆ–æ–‡ä»¶åæ ¼å¼ä¸æ­£ç¡®ï¼Œåˆ™è¿”å›Noneã€‚
    """
    try:
        # è§£ææ–‡ä»¶å
        file_info = parse_filename(uploaded_file.name)
        if not file_info:
            st.warning(f"æ–‡ä»¶å '{uploaded_file.name}' æ ¼å¼ä¸ç¬¦åˆè¦æ±‚ï¼Œå·²è·³è¿‡ã€‚")
            return None

        asin = file_info['asin']

        # è¯»å–Excelçš„ç¬¬ä¸€ä¸ªsheet
        # `sheet_name=0` è¡¨ç¤ºè¯»å–ç¬¬ä¸€ä¸ªsheet
        # `engine='openpyxl'` æ˜¯ä¸ºäº†æ›´å¥½åœ°å…¼å®¹.xlsxæ–‡ä»¶
        original_df = pd.read_excel(uploaded_file, sheet_name=0, engine='openpyxl')

        # è·å–ç¬¬ä¸€ä¸ªsheetçš„åç§°ï¼Œç”¨äºåœ¨æ–°Excelä¸­åˆ›å»ºåŒåsheet
        xls = pd.ExcelFile(uploaded_file, engine='openpyxl')
        sheet_name = xls.sheet_names[0]

        # å‡†å¤‡ç”¨äºåˆå¹¶åˆ°æ€»è¡¨çš„æ•°æ®
        df_for_consolidation = original_df.copy()
        # åœ¨ç¬¬ä¸€åˆ—æ’å…¥ASINä¿¡æ¯
        df_for_consolidation.insert(0, 'ASIN', asin)

        return sheet_name, original_df, df_for_consolidation

    except Exception as e:
        st.error(f"å¤„ç†æ–‡ä»¶ '{uploaded_file.name}' æ—¶å‡ºé”™: {e}")
        return None


def create_excel_file(individual_sheets: Dict[str, pd.DataFrame], consolidated_df: pd.DataFrame) -> BytesIO:
    """
    å°†å¤„ç†å¥½çš„æ•°æ®å†™å…¥ä¸€ä¸ªæ–°çš„Excelæ–‡ä»¶ï¼ˆåœ¨å†…å­˜ä¸­ï¼‰ã€‚

    Args:
        individual_sheets (Dict[str, pd.DataFrame]): ä¸€ä¸ªå­—å…¸ï¼Œé”®æ˜¯sheetåï¼Œå€¼æ˜¯å¯¹åº”çš„åŸå§‹DataFrameã€‚
        consolidated_df (pd.DataFrame): æ•´åˆäº†æ‰€æœ‰ASINä¿¡æ¯çš„æ€»è¡¨DataFrameã€‚

    Returns:
        BytesIO: åŒ…å«æ–°Excelæ–‡ä»¶å†…å®¹çš„äºŒè¿›åˆ¶æµå¯¹è±¡ã€‚
    """
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        # 1. å†™å…¥æ€»è¡¨ï¼Œå¹¶å°†å…¶æ”¾åœ¨ç¬¬ä¸€ä¸ª
        consolidated_df.to_excel(writer, sheet_name='æ€»è¡¨-æ‰€æœ‰ASINæ•´åˆ', index=False)

        # 2. å†™å…¥æ¯ä¸ªç‹¬ç«‹çš„ASIN sheet
        for sheet_name, df in individual_sheets.items():
            df.to_excel(writer, sheet_name=sheet_name, index=False)

    # é‡ç½®æŒ‡é’ˆåˆ°æ–‡ä»¶å¼€å¤´ï¼Œä»¥ä¾¿st.download_buttonå¯ä»¥è¯»å–å®ƒ
    output.seek(0)
    return output


# --- Streamlit é¡µé¢å¸ƒå±€ (Streamlit UI) ---

def main():
    """
    Streamlitåº”ç”¨ç¨‹åºçš„ä¸»å‡½æ•°ã€‚
    """
    st.set_page_config(page_title="Excel åˆå¹¶å·¥å…·", layout="wide")
    st.title("ğŸ“Š ASINå…³é”®è¯åæŸ¥æŠ¥å‘Šåˆå¹¶å·¥å…·")
    st.markdown("""
    **ä½¿ç”¨è¯´æ˜:**
    1.  ç‚¹å‡»ä¸‹æ–¹çš„â€œBrowse filesâ€æŒ‰é’®ï¼Œé€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªç¬¦åˆå‘½åè§„èŒƒçš„Excelæ–‡ä»¶ã€‚
    2.  æ–‡ä»¶å‘½åè§„èŒƒ: `ReverseASIN-å›½å®¶ä»£ç -ASIN(å…³é”®è¯æ•°é‡)-æ—¥æœŸ.xlsx` (ä¾‹å¦‚: `ReverseASIN-US-B01N9KSITZ(1584)-20251012.xlsx`)
    3.  é€‰æ‹©æ–‡ä»¶åï¼Œç‚¹å‡»â€œå¼€å§‹åˆå¹¶â€æŒ‰é’®ã€‚
    4.  å¤„ç†å®Œæˆåï¼Œä¸‹æ–¹ä¼šæ˜¾ç¤ºæ¦‚æ‹¬ä¿¡æ¯ï¼Œå¹¶æä¾›åˆå¹¶åæ–‡ä»¶çš„ä¸‹è½½é“¾æ¥ã€‚
    """)

    # 1. æ–‡ä»¶ä¸Šä¼ ç»„ä»¶
    uploaded_files = st.file_uploader(
        "è¯·ä¸Šä¼ éœ€è¦åˆå¹¶çš„Excelæ–‡ä»¶",
        type=['xlsx'],
        accept_multiple_files=True
    )

    # 2. åˆå¹¶æŒ‰é’®
    if st.button("ğŸš€ å¼€å§‹åˆå¹¶", type="primary"):
        if uploaded_files:
            # åˆå§‹åŒ–ç”¨äºå­˜å‚¨æ•°æ®çš„å®¹å™¨
            individual_sheets_data = {}  # key: sheetå, value: åŸå§‹DataFrame
            dfs_for_consolidation = []  # ç”¨äºå­˜æ”¾æ‰€æœ‰æ·»åŠ äº†ASINåˆ—çš„DataFrame

            # ä½¿ç”¨è¿›åº¦æ¡æå‡ç”¨æˆ·ä½“éªŒ
            progress_bar = st.progress(0)
            total_files = len(uploaded_files)

            for i, uploaded_file in enumerate(uploaded_files):
                st.write(f"ğŸ“„ æ­£åœ¨å¤„ç†æ–‡ä»¶: `{uploaded_file.name}`")
                result = process_uploaded_file(uploaded_file)

                if result:
                    sheet_name, original_df, df_with_asin = result
                    individual_sheets_data[sheet_name] = original_df
                    dfs_for_consolidation.append(df_with_asin)

                # æ›´æ–°è¿›åº¦æ¡
                progress_bar.progress((i + 1) / total_files)

            # 3. å¦‚æœæˆåŠŸå¤„ç†äº†è‡³å°‘ä¸€ä¸ªæ–‡ä»¶ï¼Œåˆ™è¿›è¡Œåˆå¹¶å’Œç”Ÿæˆ
            if dfs_for_consolidation:
                # ä½¿ç”¨concatåˆå¹¶æ‰€æœ‰DataFrame
                consolidated_df = pd.concat(dfs_for_consolidation, ignore_index=True)

                # ç”Ÿæˆæœ€ç»ˆçš„Excelæ–‡ä»¶
                excel_bytes = create_excel_file(individual_sheets_data, consolidated_df)

                # 4. è¾“å‡ºæ¦‚æ‹¬æ€§ä¿¡æ¯
                st.success("ğŸ‰ æ–‡ä»¶åˆå¹¶æˆåŠŸï¼")
                st.markdown("---")
                col1, col2, col3 = st.columns(3)
                col1.metric("åˆå¹¶æ–‡ä»¶æ€»æ•°", f"{len(individual_sheets_data)} ä¸ª")
                col2.metric("æ•´åˆåæ€»å…³é”®è¯è¡Œæ•°", f"{len(consolidated_df)} è¡Œ")
                col3.metric("ç”ŸæˆSheetæ€»æ•°", f"{len(individual_sheets_data) + 1} ä¸ª")

                # 5. æä¾›ä¸‹è½½æŒ‰é’®
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½åˆå¹¶åçš„Excelæ–‡ä»¶",
                    data=excel_bytes,
                    file_name="Merged_ASIN_Keywords.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            else:
                st.error("æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ä¸Šä¼ æ–‡ä»¶çš„æ ¼å¼å’Œå†…å®¹ã€‚")
        else:
            # å¦‚æœç”¨æˆ·æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶å°±ç‚¹å‡»æŒ‰é’®
            st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ è‡³å°‘ä¸€ä¸ªExcelæ–‡ä»¶ã€‚")


if __name__ == "__main__":
    main()