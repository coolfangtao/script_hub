import streamlit as st
import google.generativeai as genai
from shared.sidebar import create_common_sidebar
from shared.config import Config


# --- 1. é…ç½®å’Œåˆå§‹åŒ– ---

def setup_page_and_sidebar():
    """é…ç½®é¡µé¢å’Œä¾§è¾¹æ """
    st.set_page_config(
        page_title="AI å¯¹è¯",
        page_icon="ğŸ¤–",
        layout="wide"
    )
    create_common_sidebar()


def configure_api():
    """é…ç½® Google Gemini API"""
    try:
        cfg = Config()
        api_key = st.secrets[cfg.GEMINI_API_KEY]
        genai.configure(api_key=api_key)
        return True
    except Exception as e:
        st.error(f"API é…ç½®å¤±è´¥: {e}")
        return False


def initialize_chat_session(selected_model):
    """
    æ ¹æ®é€‰æ‹©çš„æ¨¡å‹åˆå§‹åŒ–æˆ–é‡ç½®èŠå¤©ä¼šè¯ã€‚
    å¦‚æœæ¨¡å‹è¢«åˆ‡æ¢ï¼Œåˆ™æ¸…ç©ºå†å²è®°å½•å¹¶å¼€å§‹æ–°çš„ä¼šè¯ã€‚
    """
    if "gemini_chat" not in st.session_state or st.session_state.get("selected_model") != selected_model:
        if "gemini_chat" in st.session_state:
            st.toast(f"æ¨¡å‹å·²åˆ‡æ¢ä¸º {selected_model}ï¼Œæ–°çš„å¯¹è¯å¼€å§‹å•¦ï¼", icon="ğŸ”„")

        st.session_state.selected_model = selected_model
        model = genai.GenerativeModel(selected_model)
        st.session_state.gemini_chat = model.start_chat(history=[])
        st.session_state.messages = []


# --- 2. æ ¸å¿ƒä¿®å¤ï¼šæµå¼æ•°æ®å¤„ç†å™¨ ---

def stream_handler(stream):
    """
    è¿™æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨å‡½æ•°ï¼Œç”¨äºå¤„ç† Gemini API è¿”å›çš„æµã€‚
    å®ƒä¼šè¿­ä»£æµä¸­çš„æ¯ä¸€ä¸ªå“åº”å—ï¼ˆchunkï¼‰ï¼Œå¹¶ä»…æå–å‡ºæ–‡æœ¬éƒ¨åˆ†ï¼ˆ.textï¼‰ã€‚
    è¿™æ ·ï¼Œst.write_stream æ¥æ”¶åˆ°çš„å°±æ˜¯ä¸€ä¸ªçº¯æ–‡æœ¬æµã€‚
    """
    for chunk in stream:
        # æ£€æŸ¥ chunk æ˜¯å¦æœ‰ text å±æ€§ï¼Œé˜²æ­¢å‡ºé”™
        if hasattr(chunk, 'text'):
            yield chunk.text


# --- 3. ä¸»åº”ç”¨ç•Œé¢ ---

def main():
    """ä¸»åº”ç”¨å‡½æ•°"""
    setup_page_and_sidebar()

    st.title("ğŸ¤– AI å¯¹è¯")
    st.caption("ä¸€ä¸ªç”± Google Gemini é©±åŠ¨çš„èŠå¤©æœºå™¨äºº")

    if not configure_api():
        st.stop()

    # --- æ¨¡å‹é€‰æ‹© ---
    cfg = Config()
    MODEL_OPTIONS = cfg.GEMINI_MODEL_OPTIONS
    selected_model = st.selectbox(
        "è¯·é€‰æ‹©ä¸€ä¸ª AI æ¨¡å‹:",
        options=MODEL_OPTIONS,
        index=0,
        help="ä¸åŒæ¨¡å‹çš„èƒ½åŠ›å’Œå“åº”é€Ÿåº¦å„å¼‚ã€‚"
    )

    initialize_chat_session(selected_model)

    # --- æ˜¾ç¤ºå†å²èŠå¤©è®°å½• ---
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # --- èŠå¤©è¾“å…¥æ¡†å’Œå“åº”å¤„ç† ---
    if prompt := st.chat_input("æ‚¨å¥½ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        try:
            with st.chat_message("assistant"):
                with st.spinner("AI æ­£åœ¨æ€è€ƒä¸­..."):
                    response_stream = st.session_state.gemini_chat.send_message(prompt, stream=True)

                    # --- è¿™é‡Œæ˜¯å…³é”®çš„æ”¹åŠ¨ ---
                    # æˆ‘ä»¬ä¸å†ç›´æ¥ä¼ é€’ response_streamï¼Œè€Œæ˜¯ä¼ é€’ç»è¿‡ stream_handler å¤„ç†åçš„çº¯æ–‡æœ¬æµ
                    full_response = st.write_stream(stream_handler(response_stream))

            st.session_state.messages.append({"role": "assistant", "content": full_response})

        except Exception as e:
            st.error(f"è°ƒç”¨ API æ—¶å‡ºé”™: {e}")


# --- 4. è¿è¡Œä¸»ç¨‹åº ---

if __name__ == "__main__":
    main()
