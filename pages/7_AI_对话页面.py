# æ–‡ä»¶è·¯å¾„: pages/7_AI_å¯¹è¯é¡µé¢.py

import streamlit as st
import google.generativeai as genai
from shared.sidebar import create_common_sidebar # å¯¼å…¥å…¬å…±ä¾§è¾¹æ å‡½æ•°
from shared.ai_model_config import MODEL_NAME

# --- é¡µé¢é…ç½®å’Œä¾§è¾¹æ  ---
st.set_page_config(
    page_title="AI å¯¹è¯",
    page_icon="ğŸ¤–"
)
create_common_sidebar() # è°ƒç”¨å‡½æ•°åˆ›å»ºä¾§è¾¹æ 

# --- API å¯†é’¥é…ç½® ---
# ä» Streamlit secrets ä¸­è·å– API å¯†é’¥
try:
    api_key = st.secrets["API_KEY"]
    genai.configure(api_key=api_key)
except (KeyError, FileNotFoundError):
    st.error("Gemini API å¯†é’¥æœªæ‰¾åˆ°ã€‚è¯·åœ¨ Streamlit secrets ä¸­è®¾ç½®åä¸º 'API_KEY' çš„å¯†é’¥ã€‚")
    st.stop()


# --- åˆå§‹åŒ–æ¨¡å‹å’Œä¼šè¯çŠ¶æ€ ---
# ä½¿ç”¨ session_state æ¥æŒä¹…åŒ–èŠå¤©è®°å½•
if "gemini_chat" not in st.session_state:
    # åˆå§‹åŒ–æ¨¡å‹
    model = genai.GenerativeModel(MODEL_NAME)
    # å¼€å§‹èŠå¤©ï¼Œå¹¶å°†ä¼šè¯å¯¹è±¡å­˜å‚¨åœ¨ session_state ä¸­
    st.session_state.gemini_chat = model.start_chat(history=[])
    # åˆå§‹åŒ–ä¸€ä¸ªåˆ—è¡¨æ¥å•ç‹¬å­˜å‚¨å’Œæ˜¾ç¤ºæ¶ˆæ¯
    st.session_state.messages = []

# --- é¡µé¢æ ‡é¢˜å’Œä»‹ç» ---
st.title("ğŸ¤– AI å¯¹è¯")
st.caption("ä¸€ä¸ªç”± Google Gemini Pro é©±åŠ¨çš„èŠå¤©æœºå™¨äºº")

# --- æ˜¾ç¤ºå†å²èŠå¤©è®°å½• ---
# éå† session_state ä¸­å­˜å‚¨çš„æ‰€æœ‰æ¶ˆæ¯å¹¶æ˜¾ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- èŠå¤©è¾“å…¥æ¡† ---
# Streamlit çš„ st.chat_input ç»„ä»¶ç”¨äºæ¥æ”¶ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("æ‚¨å¥½ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ"):
    # 1. å°†ç”¨æˆ·çš„è¾“å…¥æ·»åŠ åˆ°æ¶ˆæ¯è®°å½•ä¸­å¹¶æ˜¾ç¤º
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # 2. è°ƒç”¨ Gemini API è·å–å›å¤
    try:
        # æ˜¾ç¤ºä¸€ä¸ªåŠ è½½æŒ‡ç¤ºå™¨ï¼Œæå‡ç”¨æˆ·ä½“éªŒ
        with st.spinner("AI æ­£åœ¨æ€è€ƒä¸­..."):
            # ä½¿ç”¨å­˜å‚¨åœ¨ session_state ä¸­çš„èŠå¤©ä¼šè¯å¯¹è±¡å‘é€æ¶ˆæ¯
            response = st.session_state.gemini_chat.send_message(prompt, stream=True)
            response.resolve() # ç­‰å¾…æ‰€æœ‰æµå¼æ•°æ®å—æ¥æ”¶å®Œæ¯•

        # 3. å°† AI çš„å›å¤æ·»åŠ åˆ°æ¶ˆæ¯è®°å½•ä¸­å¹¶æ˜¾ç¤º
        ai_response = response.text
        st.session_state.messages.append({"role": "assistant", "content": ai_response})
        with st.chat_message("assistant"):
            st.markdown(ai_response)

    except Exception as e:
        st.error(f"è°ƒç”¨ API æ—¶å‡ºé”™: {e}")