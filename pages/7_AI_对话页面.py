import streamlit as st
import google.generativeai as genai
from shared.sidebar import create_common_sidebar
from shared.config import Config


# --- 1. é…ç½®å’Œåˆå§‹åŒ– ---

def setup_page_and_sidebar():
    """é…ç½®é¡µé¢å’Œä¾§è¾¹æ """
    st.set_page_config(
        page_title="AI å¯¹è¯",
        page_icon="ğŸ¤–",
        layout="wide"
    )
    create_common_sidebar()


def configure_api():
    """é…ç½® Google Gemini API"""
    try:
        cfg = Config()
        api_key = st.secrets[cfg.GEMINI_API_KEY]
        genai.configure(api_key=api_key)
        return True
    except Exception as e:
        st.error(f"API é…ç½®å¤±è´¥: {e}")
        return False


def initialize_chat_session(selected_model):
    """
    æ ¹æ®é€‰æ‹©çš„æ¨¡å‹åˆå§‹åŒ–æˆ–é‡ç½®èŠå¤©ä¼šè¯ã€‚
    å¦‚æœæ¨¡å‹è¢«åˆ‡æ¢ï¼Œåˆ™æ¸…ç©ºå†å²è®°å½•å¹¶å¼€å§‹æ–°çš„ä¼šè¯ã€‚
    """
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åˆ‡æ¢
    model_switched = "selected_model" in st.session_state and st.session_state.get("selected_model") != selected_model

    if "gemini_chat" not in st.session_state or model_switched:
        if model_switched:
            st.toast(f"æ¨¡å‹å·²åˆ‡æ¢ä¸º {selected_model}ï¼Œæ–°çš„å¯¹è¯å¼€å§‹å•¦ï¼", icon="ğŸ”„")

        st.session_state.selected_model = selected_model
        model = genai.GenerativeModel(selected_model)
        st.session_state.gemini_chat = model.start_chat(history=[])
        st.session_state.messages = []


# --- 2. æ ¸å¿ƒä¿®å¤ï¼šæµå¼æ•°æ®å¤„ç†å™¨ ---

def stream_handler(stream):
    """
    è¿™æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨å‡½æ•°ï¼Œç”¨äºå¤„ç† Gemini API è¿”å›çš„æµã€‚
    å®ƒä¼šè¿­ä»£æµä¸­çš„æ¯ä¸€ä¸ªå“åº”å—ï¼ˆchunkï¼‰ï¼Œå¹¶ä»…æå–å‡ºæ–‡æœ¬éƒ¨åˆ†ï¼ˆ.textï¼‰ã€‚
    è¿™æ ·ï¼Œst.write_stream æ¥æ”¶åˆ°çš„å°±æ˜¯ä¸€ä¸ªçº¯æ–‡æœ¬æµã€‚
    """
    for chunk in stream:
        # æ£€æŸ¥ chunk æ˜¯å¦æœ‰ text å±æ€§ï¼Œé˜²æ­¢å‡ºé”™
        if hasattr(chunk, 'text'):
            yield chunk.text


# --- 3. ä¸»åº”ç”¨ç•Œé¢ ---

def main():
    """ä¸»åº”ç”¨å‡½æ•°"""
    setup_page_and_sidebar()

    st.title("ğŸ¤– AI å¯¹è¯")
    st.caption("ä¸€ä¸ªç”± Google Gemini é©±åŠ¨çš„èŠå¤©æœºå™¨äºº")

    if not configure_api():
        st.stop()

    cfg = Config()
    MODEL_OPTIONS = cfg.GEMINI_MODEL_OPTIONS

    # --- MODIFICATION 1 START: å°†æ¨¡å‹é€‰æ‹©å’Œæ¸…é™¤æŒ‰é’®æ”¾åˆ°æŒ‡å®šä½ç½® ---
    # å°†æ¨¡å‹é€‰æ‹©æ”¾åˆ°å·¦ä¸Šè§’
    top_left_col, _ = st.columns([1, 3])
    with top_left_col:
        selected_model = st.selectbox(
            "è¯·é€‰æ‹©ä¸€ä¸ª AI æ¨¡å‹:",
            options=MODEL_OPTIONS,
            index=0,
            key="model_selector",  # æ·»åŠ ä¸€ä¸ªkeyä»¥ç¨³å®šç»„ä»¶
            help="ä¸åŒæ¨¡å‹çš„èƒ½åŠ›å’Œå“åº”é€Ÿåº¦å„å¼‚ã€‚"
        )

    # åœ¨ä¾§è¾¹æ æ·»åŠ æ¸…é™¤æŒ‰é’®
    with st.sidebar:
        st.header("å¯¹è¯æ§åˆ¶")
        if st.button("æ¸…é™¤å½“å‰å¯¹è¯", use_container_width=True, type="primary"):
            # è°ƒç”¨åˆå§‹åŒ–å‡½æ•°é‡ç½®ä¼šè¯
            initialize_chat_session(selected_model)
            st.toast("å¯¹è¯å·²æ¸…é™¤ï¼", icon="ğŸ§¹")
            st.rerun()
    # --- MODIFICATION 1 END ---

    initialize_chat_session(selected_model)

    # --- æ˜¾ç¤ºå†å²èŠå¤©è®°å½• ---
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # --- MODIFICATION 2 START: æ ¹æ®æ˜¯å¦æœ‰å¯¹è¯å†å²ï¼Œå†³å®šè¾“å…¥æ¡†ä½ç½® ---
    prompt = None
    # å¦‚æœæ²¡æœ‰æ¶ˆæ¯ï¼Œè¯´æ˜æ˜¯æ–°ä¼šè¯ï¼Œå°†è¾“å…¥æ¡†å±…ä¸­
    if not st.session_state.messages:
        # ä½¿ç”¨ä¸€ä¸ªå®¹å™¨å’Œç©ºè¡Œå°†è¾“å…¥æ¡†åœ¨å‚ç›´æ–¹å‘ä¸Šå±…ä¸­ä¸€äº›
        with st.container():
            st.markdown("<br><br><br><br>", unsafe_allow_html=True)  # å¢åŠ ä¸€äº›å‚ç›´ç©ºé—´
            _, center_col, _ = st.columns([1, 2, 1])
            with center_col:
                prompt = st.chat_input("æ‚¨å¥½ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ", key="centered_chat_input")
    # å¦‚æœæœ‰æ¶ˆæ¯ï¼Œè¾“å…¥æ¡†è‡ªåŠ¨ç½®äºåº•éƒ¨
    else:
        prompt = st.chat_input("ç»§ç»­æé—®...", key="bottom_chat_input")
    # --- MODIFICATION 2 END ---

    # --- ç»Ÿä¸€çš„èŠå¤©è¾“å…¥å’Œå“åº”å¤„ç†é€»è¾‘ ---
    if prompt:
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        try:
            with st.chat_message("assistant"):
                with st.spinner("AI æ­£åœ¨æ€è€ƒä¸­..."):
                    response_stream = st.session_state.gemini_chat.send_message(prompt, stream=True)
                    # ä½¿ç”¨ st.write_stream æ¥å¤„ç†æµå¼å“åº”
                    full_response = st.write_stream(stream_handler(response_stream))
            st.session_state.messages.append({"role": "assistant", "content": full_response})

            # å¦‚æœæ˜¯ä»å±…ä¸­è¾“å…¥æ¡†å¼€å§‹çš„å¯¹è¯ï¼Œéœ€è¦åˆ·æ–°é¡µé¢ä»¥å°†è¾“å…¥æ¡†ç§»åˆ°åº•éƒ¨
            if len(st.session_state.messages) == 2:  # ç¬¬ä¸€æ¬¡æé—®åï¼Œæ€»å…±æœ‰2æ¡æ¶ˆæ¯(user+assistant)
                st.rerun()

        except Exception as e:
            st.error(f"è°ƒç”¨ API æ—¶å‡ºé”™: {e}")


# --- 4. è¿è¡Œä¸»ç¨‹åº ---

if __name__ == "__main__":
    main()