import streamlit as st
import google.generativeai as genai
from shared.sidebar import create_common_sidebar
from shared.config import Config


# --- 1. é…ç½®å’Œåˆå§‹åŒ– ---

def setup_page_and_sidebar():
    """é…ç½®é¡µé¢å’Œä¾§è¾¹æ """
    st.set_page_config(
        page_title="AI å¯¹è¯",
        page_icon="ğŸ¤–",
        layout="wide"
    )
    # è¿™ä¸ªå…¬å…±ä¾§è¾¹æ å‡½æ•°ä¿æŒä¸å˜
    create_common_sidebar()


def configure_api():
    """é…ç½® Google Gemini API"""
    try:
        cfg = Config()
        api_key = st.secrets[cfg.GEMINI_API_KEY]
        genai.configure(api_key=api_key)
        return True
    except Exception as e:
        st.error(f"API é…ç½®å¤±è´¥: {e}")
        return False


def initialize_chat_session(selected_model):
    """
    æ ¹æ®é€‰æ‹©çš„æ¨¡å‹åˆå§‹åŒ–æˆ–é‡ç½®èŠå¤©ä¼šè¯ã€‚
    å¦‚æœæ¨¡å‹è¢«åˆ‡æ¢ï¼Œåˆ™æ¸…ç©ºå†å²è®°å½•å¹¶å¼€å§‹æ–°çš„ä¼šè¯ã€‚
    """
    model_switched = "selected_model" in st.session_state and st.session_state.get("selected_model") != selected_model

    if "gemini_chat" not in st.session_state or model_switched:
        if model_switched:
            st.toast(f"æ¨¡å‹å·²åˆ‡æ¢ä¸º {selected_model}ï¼Œæ–°çš„å¯¹è¯å¼€å§‹å•¦ï¼", icon="ğŸ”„")

        st.session_state.selected_model = selected_model
        model = genai.GenerativeModel(selected_model)
        st.session_state.gemini_chat = model.start_chat(history=[])
        st.session_state.messages = []


# --- 2. æ ¸å¿ƒä¿®å¤ï¼šæµå¼æ•°æ®å¤„ç†å™¨ ---

def stream_handler(stream):
    """
    è¿™æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨å‡½æ•°ï¼Œç”¨äºå¤„ç† Gemini API è¿”å›çš„æµã€‚
    å®ƒä¼šè¿­ä»£æµä¸­çš„æ¯ä¸€ä¸ªå“åº”å—ï¼ˆchunkï¼‰ï¼Œå¹¶ä»…æå–å‡ºæ–‡æœ¬éƒ¨åˆ†ï¼ˆ.textï¼‰ã€‚
    è¿™æ ·ï¼Œst.write_stream æ¥æ”¶åˆ°çš„å°±æ˜¯ä¸€ä¸ªçº¯æ–‡æœ¬æµã€‚
    """
    for chunk in stream:
        if hasattr(chunk, 'text'):
            yield chunk.text


# --- 3. ä¸»åº”ç”¨ç•Œé¢ ---

def main():
    """ä¸»åº”ç”¨å‡½æ•°"""
    setup_page_and_sidebar()

    st.title("ğŸ¤– AI å¯¹è¯")
    st.caption("ä¸€ä¸ªç”± Google Gemini é©±åŠ¨çš„èŠå¤©æœºå™¨äºº")

    if not configure_api():
        st.stop()

    cfg = Config()
    MODEL_OPTIONS = cfg.GEMINI_MODEL_OPTIONS

    # --- MODIFICATION START: å°†æ¨¡å‹é€‰æ‹©å’Œæ¸…é™¤æŒ‰é’®åˆ†åˆ«æ”¾ç½®åœ¨é¡µé¢å·¦ä¸Šè§’å’Œå³ä¸Šè§’ ---
    # ä½¿ç”¨åˆ—å¸ƒå±€æ¥æ”¾ç½®å·¦ä¾§çš„é€‰æ‹©æ¡†å’Œå³ä¾§çš„æŒ‰é’®
    col1, col_spacer, col2 = st.columns([2, 5, 2])  # è°ƒæ•´æ¯”ä¾‹ä»¥è·å¾—æœ€ä½³è§†è§‰æ•ˆæœ

    with col1:
        selected_model = st.selectbox(
            "è¯·é€‰æ‹©ä¸€ä¸ª AI æ¨¡å‹:",
            options=MODEL_OPTIONS,
            index=0,
            key="model_selector",
            label_visibility="collapsed",  # éšè—æ ‡ç­¾ä»¥èŠ‚çœç©ºé—´
            help="ä¸åŒæ¨¡å‹çš„èƒ½åŠ›å’Œå“åº”é€Ÿåº¦å„å¼‚ã€‚"
        )

    with col2:
        # æ·»åŠ ä¸€ç‚¹å‚ç›´ç©ºé—´ï¼Œè®©æŒ‰é’®å’Œé€‰æ‹©æ¡†å¤§è‡´å¯¹é½
        st.write("")
        if st.button("æ¸…é™¤å½“å‰å¯¹è¯", use_container_width=True):
            initialize_chat_session(selected_model)
            st.toast("å¯¹è¯å·²æ¸…é™¤ï¼", icon="ğŸ§¹")
            st.rerun()
    # --- MODIFICATION END ---

    initialize_chat_session(selected_model)

    # --- æ˜¾ç¤ºå†å²èŠå¤©è®°å½• ---
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # --- æ ¹æ®æ˜¯å¦æœ‰å¯¹è¯å†å²ï¼Œå†³å®šè¾“å…¥æ¡†ä½ç½® ---
    prompt = None
    if not st.session_state.messages:
        with st.container():
            st.markdown("<br><br><br><br>", unsafe_allow_html=True)
            _, center_col, _ = st.columns([1, 2, 1])
            with center_col:
                prompt = st.chat_input("æ‚¨å¥½ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ", key="centered_chat_input")
    else:
        prompt = st.chat_input("ç»§ç»­æé—®...", key="bottom_chat_input")

    # --- ç»Ÿä¸€çš„èŠå¤©è¾“å…¥å’Œå“åº”å¤„ç†é€»è¾‘ ---
    if prompt:
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        try:
            with st.chat_message("assistant"):
                with st.spinner("AI æ­£åœ¨æ€è€ƒä¸­..."):
                    response_stream = st.session_state.gemini_chat.send_message(prompt, stream=True)
                    full_response = st.write_stream(stream_handler(response_stream))
            st.session_state.messages.append({"role": "assistant", "content": full_response})

            if len(st.session_state.messages) == 2:
                st.rerun()

        except Exception as e:
            st.error(f"è°ƒç”¨ API æ—¶å‡ºé”™: {e}")


# --- 4. è¿è¡Œä¸»ç¨‹åº ---

if __name__ == "__main__":
    main()