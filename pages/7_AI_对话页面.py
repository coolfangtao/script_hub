import streamlit as st
import google.generativeai as genai
from shared.sidebar import create_common_sidebar
from shared.config import Config


# --- 1. é…ç½®å’Œåˆå§‹åŒ– ---

def setup_page_and_sidebar():
    """é…ç½®é¡µé¢å’Œä¾§è¾¹æ """
    st.set_page_config(
        page_title="AI å¯¹è¯",
        page_icon="ğŸ¤–",
        layout="wide"
    )
    create_common_sidebar()


def configure_api():
    """é…ç½® Google Gemini API"""
    try:
        cfg = Config()
        api_key = st.secrets[cfg.GEMINI_API_KEY]
        genai.configure(api_key=api_key)
        return True
    except Exception as e:
        st.error(f"API é…ç½®å¤±è´¥: {e}")
        return False


def initialize_chat_session(selected_model):
    """
    æ ¹æ®é€‰æ‹©çš„æ¨¡å‹åˆå§‹åŒ–æˆ–é‡ç½®èŠå¤©ä¼šè¯ã€‚
    å¦‚æœæ¨¡å‹è¢«åˆ‡æ¢ï¼Œåˆ™æ¸…ç©ºå†å²è®°å½•å¹¶å¼€å§‹æ–°çš„ä¼šè¯ã€‚
    """
    model_switched = "selected_model" in st.session_state and st.session_state.get("selected_model") != selected_model

    if "gemini_chat" not in st.session_state or model_switched:
        if model_switched:
            st.toast(f"æ¨¡å‹å·²åˆ‡æ¢ä¸º {selected_model}ï¼Œæ–°çš„å¯¹è¯å¼€å§‹å•¦ï¼", icon="ğŸ”„")

        st.session_state.selected_model = selected_model
        model = genai.GenerativeModel(selected_model)
        st.session_state.gemini_chat = model.start_chat(history=[])
        st.session_state.messages = []


# --- 2. æ ¸å¿ƒä¿®å¤ï¼šæµå¼æ•°æ®å¤„ç†å™¨ ---

def stream_handler(stream):
    """
    è¿™æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨å‡½æ•°ï¼Œç”¨äºå¤„ç† Gemini API è¿”å›çš„æµã€‚
    å®ƒä¼šè¿­ä»£æµä¸­çš„æ¯ä¸€ä¸ªå“åº”å—ï¼ˆchunkï¼‰ï¼Œå¹¶ä»…æå–å‡ºæ–‡æœ¬éƒ¨åˆ†ï¼ˆ.textï¼‰ã€‚
    è¿™æ ·ï¼Œst.write_stream æ¥æ”¶åˆ°çš„å°±æ˜¯ä¸€ä¸ªçº¯æ–‡æœ¬æµã€‚
    """
    for chunk in stream:
        if hasattr(chunk, 'text'):
            yield chunk.text


# --- 3. ä¸»åº”ç”¨ç•Œé¢ ---

def main():
    """ä¸»åº”ç”¨å‡½æ•°"""
    setup_page_and_sidebar()

    st.title("ğŸ¤– AI å¯¹è¯")
    st.caption("ä¸€ä¸ªç”± Google Gemini é©±åŠ¨çš„èŠå¤©æœºå™¨äºº")

    if not configure_api():
        st.stop()

    cfg = Config()
    MODEL_OPTIONS = cfg.GEMINI_MODEL_OPTIONS

    # --- é¡¶éƒ¨å¸ƒå±€ï¼šå·¦ä¾§æ¨¡å‹é€‰æ‹©ï¼Œå³ä¾§æ¸…é™¤æŒ‰é’® ---
    col1, col_spacer, col2 = st.columns([2, 5, 2])

    with col1:
        selected_model = st.selectbox(
            "è¯·é€‰æ‹©ä¸€ä¸ª AI æ¨¡å‹:",
            options=MODEL_OPTIONS,
            index=0,
            key="model_selector",
            label_visibility="collapsed",
            help="ä¸åŒæ¨¡å‹çš„èƒ½åŠ›å’Œå“åº”é€Ÿåº¦å„å¼‚ã€‚"
        )

    with col2:
        st.write("")
        if st.button("æ¸…é™¤å½“å‰å¯¹è¯", use_container_width=True):
            initialize_chat_session(selected_model)
            st.toast("å¯¹è¯å·²æ¸…é™¤ï¼", icon="ğŸ§¹")
            st.rerun()

    initialize_chat_session(selected_model)

    # --- æ˜¾ç¤ºå†å²èŠå¤©è®°å½• ---
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # --- MODIFICATION REVERTED: å°†èŠå¤©è¾“å…¥æ¡†æ¢å¤ä¸ºå§‹ç»ˆåœ¨åº•éƒ¨ ---
    # ç§»é™¤äº†æ ¹æ®æ˜¯å¦æœ‰å¯¹è¯å†å²æ¥æ”¹å˜è¾“å…¥æ¡†ä½ç½®çš„å¤æ‚é€»è¾‘ã€‚
    # ç°åœ¨è¾“å…¥æ¡†å°†å§‹ç»ˆå›ºå®šåœ¨é¡µé¢åº•éƒ¨ï¼Œè¿™æ˜¯æœ€ç¨³å®šå¯é çš„æ–¹å¼ã€‚
    if prompt := st.chat_input("æ‚¨å¥½ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        try:
            with st.chat_message("assistant"):
                with st.spinner("AI æ­£åœ¨æ€è€ƒä¸­..."):
                    response_stream = st.session_state.gemini_chat.send_message(prompt, stream=True)
                    full_response = st.write_stream(stream_handler(response_stream))
            st.session_state.messages.append({"role": "assistant", "content": full_response})

            # åŒæ ·ç§»é™¤äº†ä¹‹å‰ç”¨äºåˆ‡æ¢è¾“å…¥æ¡†ä½ç½®çš„ st.rerun() è°ƒç”¨

        except Exception as e:
            st.error(f"è°ƒç”¨ API æ—¶å‡ºé”™: {e}")


# --- 4. è¿è¡Œä¸»ç¨‹åº ---

if __name__ == "__main__":
    main()