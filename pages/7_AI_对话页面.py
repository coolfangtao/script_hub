import streamlit as st
import google.generativeai as genai
from shared.sidebar import create_common_sidebar
from shared.config import Config


# --- 1. é…ç½®å’Œåˆå§‹åŒ– ---

def setup_page_and_sidebar():
    """é…ç½®é¡µé¢å’Œä¾§è¾¹æ """
    st.set_page_config(
        page_title="AI å¯¹è¯",
        page_icon="ğŸ¤–",
        layout="wide"
    )
    create_common_sidebar()


def configure_api():
    """é…ç½® Google Gemini API"""
    try:
        cfg = Config()
        api_key = st.secrets[cfg.GEMINI_API_KEY]
        genai.configure(api_key=api_key)
        return True
    except Exception as e:
        st.error(f"API é…ç½®å¤±è´¥: {e}")
        return False


def initialize_session_state():
    """åˆå§‹åŒ–æˆ–æ£€æŸ¥ä¼šè¯çŠ¶æ€"""
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "selected_model" not in st.session_state:
        st.session_state.selected_model = None


# --- BUG 1 FIX: åˆ›å»ºä¸€ä¸ªä¸“é—¨çš„æ¸…é™¤å†å²è®°å½•çš„å‡½æ•° ---
def clear_chat_history():
    """æ¸…é™¤æ‰€æœ‰èŠå¤©è®°å½•å’Œç›¸å…³çš„ä¼šè¯çŠ¶æ€"""
    st.session_state.messages = []
    # ç§»é™¤äº†å¯¹æ—§çš„ gemini_chat å¯¹è±¡çš„ä¾èµ–


# --- 2. æ ¸å¿ƒé€»è¾‘å¤„ç†å™¨ ---

def stream_handler(stream):
    """å¤„ç†APIè¿”å›çš„æµå¼æ•°æ®ï¼Œä»…æå–æ–‡æœ¬éƒ¨åˆ†"""
    for chunk in stream:
        if hasattr(chunk, 'text'):
            yield chunk.text


# --- 3. ä¸»åº”ç”¨ç•Œé¢ ---

def main():
    """ä¸»åº”ç”¨å‡½æ•°"""
    setup_page_and_sidebar()
    initialize_session_state()

    st.title("ğŸ¤– AI å¯¹è¯")
    st.caption("ä¸€ä¸ªç”± Google Gemini é©±åŠ¨çš„èŠå¤©æœºå™¨äºº")

    if not configure_api():
        st.stop()

    cfg = Config()
    MODEL_OPTIONS = cfg.GEMINI_MODEL_OPTIONS

    # --- é¡¶éƒ¨å¸ƒå±€ï¼šå·¦ä¾§æ¨¡å‹é€‰æ‹©ï¼Œå³ä¾§æ¸…é™¤æŒ‰é’® ---
    col1, col_spacer, col2 = st.columns([2, 5, 2])

    with col1:
        # å½“æ¨¡å‹é€‰æ‹©å˜åŒ–æ—¶ï¼Œè‡ªåŠ¨æ¸…é™¤å†å²è®°å½•
        def on_model_change():
            if st.session_state.selected_model != st.session_state.model_selector:
                clear_chat_history()
                st.toast(f"æ¨¡å‹å·²åˆ‡æ¢ï¼Œæ–°çš„å¯¹è¯å¼€å§‹å•¦ï¼", icon="ğŸ”„")

        selected_model = st.selectbox(
            "è¯·é€‰æ‹©ä¸€ä¸ª AI æ¨¡å‹:",
            options=MODEL_OPTIONS,
            key="model_selector",
            on_change=on_model_change,
            help="åˆ‡æ¢æ¨¡å‹ä¼šè‡ªåŠ¨å¼€å§‹æ–°çš„å¯¹è¯ã€‚"
        )
        st.session_state.selected_model = selected_model

    with col2:
        st.write("")
        if st.button("æ¸…é™¤å½“å‰å¯¹è¯", use_container_width=True):
            clear_chat_history()
            st.toast("å¯¹è¯å·²æ¸…é™¤ï¼", icon="ğŸ§¹")
            st.rerun()

    # --- æ˜¾ç¤ºå†å²èŠå¤©è®°å½• ---
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # --- èŠå¤©è¾“å…¥æ¡†å’Œå“åº”å¤„ç† ---
    if prompt := st.chat_input("æ‚¨å¥½ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        try:
            with st.chat_message("assistant"):
                with st.spinner("AI æ­£åœ¨æ€è€ƒä¸­..."):
                    model = genai.GenerativeModel(selected_model)

                    # --- BUG 2 FIX: ä½¿ç”¨ st.session_state.messages ä½œä¸ºå”¯ä¸€å¯ä¿¡çš„å†å²æ¥æº ---
                    # è½¬æ¢æˆ‘ä»¬çš„æ¶ˆæ¯æ ¼å¼ä¸º Gemini API éœ€è¦çš„æ ¼å¼
                    # Gemini API ä½¿ç”¨ 'model' ä»£è¡¨ 'assistant'
                    gemini_history = [
                        {"role": "model" if msg["role"] == "assistant" else "user", "parts": [msg["content"]]}
                        for msg in st.session_state.messages[:-1]  # å‘é€é™¤æœ€æ–°ç”¨æˆ·æ¶ˆæ¯å¤–çš„æ‰€æœ‰å†å²
                    ]

                    chat = model.start_chat(history=gemini_history)
                    response_stream = chat.send_message(prompt, stream=True)

                    full_response = st.write_stream(stream_handler(response_stream))

            # å°†å®Œæ•´çš„åŠ©ç†å›å¤æ·»åŠ åˆ°å†å²è®°å½•ä¸­
            st.session_state.messages.append({"role": "assistant", "content": full_response})

        except Exception as e:
            st.error(f"è°ƒç”¨ API æ—¶å‡ºé”™: {e}")
            # å¦‚æœå‡ºé”™ï¼Œç§»é™¤åˆšåˆšæ·»åŠ çš„ç”¨æˆ·æ¶ˆæ¯ï¼Œä»¥ä¿æŒåŒæ­¥
            st.session_state.messages.pop()


# --- 4. è¿è¡Œä¸»ç¨‹åº ---
if __name__ == "__main__":
    main()