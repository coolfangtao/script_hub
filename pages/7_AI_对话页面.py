import streamlit as st
import google.generativeai as genai
from typing import List

# å¯¼å…¥æ‚¨è‡ªå®šä¹‰çš„å…±äº«æ¨¡å—
from shared.sidebar import create_common_sidebar
from shared.config import Config

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="Gemini AI å¯¹è¯",
    page_icon="âœ¨",
    layout="wide"
)

# --- å®ä¾‹åŒ–é…ç½® ---
# ä¸¥æ ¼éµå¾ªæ‚¨çš„è¦æ±‚ï¼Œä½¿ç”¨ Config ç±»
cfg = Config()

# --- API å¯†é’¥é…ç½® ---
# å°†å¯†é’¥é…ç½®æ”¾åœ¨ä¸»é€»è¾‘ä¹‹å¤–ï¼Œç¡®ä¿åœ¨åº”ç”¨å¯åŠ¨æ—¶é¦–å…ˆæ£€æŸ¥
try:
    api_key = st.secrets[cfg.GEMINI_API_KEY]
    genai.configure(api_key=api_key)
except (KeyError, FileNotFoundError):
    st.error(f"Gemini API å¯†é’¥æœªæ‰¾åˆ°ã€‚è¯·åœ¨ Streamlit secrets ä¸­è®¾ç½®ä¸€ä¸ªåä¸º '{cfg.GEMINI_API_KEY}' çš„å¯†é’¥ã€‚")
    st.info("åœ¨æœ¬åœ°è¿è¡Œæ—¶ï¼Œå¯ä»¥åˆ›å»ºä¸€ä¸ª `.streamlit/secrets.toml` æ–‡ä»¶å¹¶æ·»åŠ  `GEMINI_API_KEY = 'YOUR_API_KEY'`ã€‚")
    st.stop()


# --- é€šç”¨å‡½æ•° ---

@st.cache_data(show_spinner="æ­£åœ¨åŠ è½½ AI æ¨¡å‹åˆ—è¡¨...")
def get_available_models() -> List[str]:
    """é€šè¿‡ API åŠ¨æ€è·å–æ‰€æœ‰å¯ç”¨çš„ Gemini æ¨¡å‹åˆ—è¡¨ï¼Œå¹¶è¿›è¡Œç­›é€‰"""
    try:
        return [
            m.name.split('/')[-1]
            for m in genai.list_models()
            if "generateContent" in m.supported_generation_methods and 'gemini' in m.name
        ]
    except Exception as e:
        st.warning(f"æ— æ³•åŠ¨æ€è·å–æ¨¡å‹åˆ—è¡¨: {e}\n\nå°†ä½¿ç”¨é¢„è®¾çš„å¤‡ç”¨åˆ—è¡¨ã€‚")
        # æä¾›ä¸€ä¸ªå¤‡ç”¨åˆ—è¡¨ä»¥é˜² API è°ƒç”¨å¤±è´¥
        return ["gemini-1.5-flash", "gemini-1.5-pro", "gemini-1.0-pro"]


def initialize_chat(model_name: str) -> None:
    """åˆå§‹åŒ–æˆ–é‡ç½®èŠå¤©ä¼šè¯"""
    st.session_state.selected_model = model_name
    model = genai.GenerativeModel(model_name)
    st.session_state.gemini_chat = model.start_chat(history=[])
    st.session_state.messages = []


# --- ä¸»åº”ç”¨ ---

def main():
    # --- ä¾§è¾¹æ  ---
    # ä¸¥æ ¼éµå¾ªæ‚¨çš„è¦æ±‚ï¼Œè°ƒç”¨å…¬å…±ä¾§è¾¹æ å‡½æ•°
    create_common_sidebar()

    # åœ¨å…¬å…±ä¾§è¾¹æ ä¸‹æ–¹ï¼Œæ·»åŠ æ­¤é¡µé¢ä¸“å±çš„æ§ä»¶
    with st.sidebar:
        st.divider()  # æ·»åŠ ä¸€æ¡åˆ†å‰²çº¿ï¼ŒåŒºåˆ†å…¬å…±éƒ¨åˆ†å’Œé¡µé¢ä¸“å±éƒ¨åˆ†
        st.subheader("å½“å‰é¡µé¢è®¾ç½®")
        if st.button("ğŸ—‘ï¸ æ¸…é™¤å½“å‰å¯¹è¯", use_container_width=True):
            if "selected_model" in st.session_state:
                initialize_chat(st.session_state.selected_model)
                st.rerun()

    # --- é¡µé¢æ ‡é¢˜å’Œä»‹ç» ---
    st.title("ğŸ¤– Gemini AI å¯¹è¯")
    st.caption("ä¸€ä¸ªç”± Google Gemini Pro é©±åŠ¨çš„èŠå¤©æœºå™¨äºº")

    # --- é«˜çº§è®¾ç½® (æ¨¡å‹é€‰æ‹©) ---
    with st.expander("âš™ï¸ æ¨¡å‹é€‰æ‹©ä¸è®¾ç½®", expanded=False):
        model_options = get_available_models()
        default_model = "gemini-1.5-flash"
        default_index = model_options.index(default_model) if default_model in model_options else 0

        selected_model = st.selectbox(
            "é€‰æ‹©ä¸€ä¸ª AI æ¨¡å‹:",
            options=model_options,
            index=default_index,
            help="æ›´æ”¹æ¨¡å‹å°†ä¼šè‡ªåŠ¨å¼€å§‹ä¸€ä¸ªæ–°çš„å¯¹è¯ã€‚"
        )

    # --- åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ ---
    if "gemini_chat" not in st.session_state or st.session_state.get("selected_model") != selected_model:
        initialize_chat(selected_model)
        st.toast(f"æ¨¡å‹å·²åˆ‡æ¢ä¸º `{selected_model}`", icon="ğŸ§ ")

    # --- æ˜¾ç¤ºå†å²èŠå¤©è®°å½• ---
    for message in st.session_state.get("messages", []):
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # --- èŠå¤©è¾“å…¥æ¡† ---
    if prompt := st.chat_input("ä½ å¥½ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„å—ï¼Ÿ"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # è°ƒç”¨ Gemini API å¹¶ä»¥æµå¼æ–¹å¼æ˜¾ç¤ºå›å¤
        try:
            with st.chat_message("assistant"):
                with st.spinner("AI æ­£åœ¨æ€è€ƒä¸­..."):
                    response_stream = st.session_state.gemini_chat.send_message(prompt, stream=True)
                    # ä½¿ç”¨ st.write_stream ä¼˜é›…åœ°å¤„ç†æµå¼è¾“å‡º
                    full_response = st.write_stream(response_stream)

            # å°†å®Œæ•´çš„ AI å›å¤æ·»åŠ åˆ°æ¶ˆæ¯è®°å½•ä¸­
            st.session_state.messages.append({"role": "assistant", "content": full_response})

        except Exception as e:
            st.error(f"è°ƒç”¨ API æ—¶å‡ºé”™: {e}")


if __name__ == "__main__":
    main()