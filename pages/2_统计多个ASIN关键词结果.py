import streamlit as st
import pandas as pd
import plotly.express as px
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from shared.sidebar import create_sidebar # <-- 1. å¯¼å…¥å‡½æ•°
create_sidebar() # <-- 2. è°ƒç”¨å‡½æ•°ï¼Œç¡®ä¿æ¯ä¸ªé¡µé¢éƒ½æœ‰ä¾§è¾¹æ 

# --- 1. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---
def load_merged_data(uploaded_file):
    """
    åŠ è½½ä¸Šä¼ çš„Excelæ–‡ä»¶ï¼Œå¹¶ä¸“é—¨è¯»å–åä¸º'æ€»è¡¨-æ‰€æœ‰ASINæ•´åˆ'çš„sheetã€‚
    """
    if uploaded_file is not None:
        try:
            # è¯»å–æŒ‡å®šçš„sheet
            df = pd.read_excel(uploaded_file, sheet_name='æ€»è¡¨-æ‰€æœ‰ASINæ•´åˆ', engine='openpyxl')
            return df
        except ValueError:
            st.error("é”™è¯¯ï¼šä¸Šä¼ çš„Excelæ–‡ä»¶ä¸­æœªæ‰¾åˆ°åä¸º 'æ€»è¡¨-æ‰€æœ‰ASINæ•´åˆ' çš„Sheetã€‚è¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹ã€‚")
            return None
        except Exception as e:
            st.error(f"åŠ è½½æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return None
    return None

def clean_data(df):
    """
    å¯¹æ•°æ®è¿›è¡Œæ¸…æ´—ï¼Œç‰¹åˆ«æ˜¯å°†å…³é”®æŒ‡æ ‡åˆ—è½¬æ¢ä¸ºæ•°å€¼ç±»å‹ã€‚
    """
    # å®šä¹‰éœ€è¦è½¬æ¢ä¸ºæ•°å€¼çš„åˆ—
    numeric_cols = ['æµé‡å æ¯”', 'é¢„ä¼°å‘¨æ›å…‰é‡', 'éœ€ä¾›æ¯”', 'è´­ä¹°é‡', 'è´­ä¹°ç‡']
    for col in numeric_cols:
        if col in df.columns:
            # 'è´­ä¹°ç‡' å¯èƒ½åŒ…å«ç™¾åˆ†å·ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
            if df[col].dtype == 'object' and col == 'è´­ä¹°ç‡':
                df[col] = df[col].astype(str).str.replace('%', '', regex=False)

            df[col] = pd.to_numeric(df[col], errors='coerce')

            # å¦‚æœæ˜¯è´­ä¹°ç‡ï¼Œè½¬æ¢å›ç™¾åˆ†æ¯”å°æ•°
            if col == 'è´­ä¹°ç‡':
                 df[col] = df[col] / 100
    return df


def display_metrics(df):
    """
    æ ¹æ®ç­›é€‰åçš„æ•°æ®ï¼Œè®¡ç®—å¹¶å±•ç¤ºæ ¸å¿ƒä¸šåŠ¡æŒ‡æ ‡ã€‚
    """
    st.header("æ ¸å¿ƒæŒ‡æ ‡æ¦‚è§ˆ (å·²èšåˆ)")

    if df.empty:
        st.warning("å½“å‰ç­›é€‰æ¡ä»¶ä¸‹æ— æ•°æ®ã€‚")
        return

    # è®¡ç®—æŒ‡æ ‡
    total_weekly_impressions = df['é¢„ä¼°å‘¨æ›å…‰é‡'].sum()
    average_supply_demand_ratio = df['éœ€ä¾›æ¯”'].mean()
    total_purchase = df['è´­ä¹°é‡'].sum()
    # è´­ä¹°ç‡çš„å¹³å‡å€¼åº”è¯¥åŸºäºæ€»è´­ä¹°é‡/æ€»ç‚¹å‡»é‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰ï¼Œè¿™é‡Œä¸ºç®€åŒ–å…ˆç”¨å¹³å‡å€¼
    average_purchase_rate = df['è´­ä¹°ç‡'].mean()

    # åˆ›å»ºåˆ—æ¥å¹¶æ’æ˜¾ç¤ºæŒ‡æ ‡
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("é¢„ä¼°å‘¨æ›å…‰æ€»é‡", f"{int(total_weekly_impressions):,}")
    col2.metric("å¹³å‡éœ€ä¾›æ¯”", f"{average_supply_demand_ratio:.2f}")
    col3.metric("å…³é”®è¯æ€»è´­ä¹°é‡", f"{int(total_purchase):,}")
    col4.metric("å¹³å‡è´­ä¹°ç‡", f"{average_purchase_rate:.2%}")


def plot_asin_contribution(df):
    """
    (æ–°å¢åŠŸèƒ½) ç»˜åˆ¶å„ASINçš„æµé‡è´¡çŒ®å¯¹æ¯”å›¾ã€‚
    """
    st.subheader("å„ASINæµé‡è´¡çŒ®å¯¹æ¯”")
    if df.empty or 'ASIN' not in df.columns:
        st.warning("æ— æ•°æ®æ˜¾ç¤ºæˆ–ç¼ºå°‘ASINåˆ—ã€‚")
        return

    # æŒ‰ASINåˆ†ç»„ï¼Œè®¡ç®—æ¯ä¸ªASINçš„é¢„ä¼°å‘¨æ›å…‰é‡æ€»å’Œ
    asin_performance = df.groupby('ASIN')['é¢„ä¼°å‘¨æ›å…‰é‡'].sum().sort_values(ascending=False).reset_index()

    fig = px.bar(
        asin_performance,
        x='ASIN',
        y='é¢„ä¼°å‘¨æ›å…‰é‡',
        title='å„ASINæ€»é¢„ä¼°å‘¨æ›å…‰é‡å¯¹æ¯”',
        labels={'é¢„ä¼°å‘¨æ›å…‰é‡': 'é¢„ä¼°å‘¨æ›å…‰é‡æ€»å’Œ', 'ASIN': 'ASIN'},
        text='é¢„ä¼°å‘¨æ›å…‰é‡'
    )
    fig.update_traces(texttemplate='%{text:.2s}', textposition='outside')
    fig.update_layout(xaxis_tickangle=-45)
    st.plotly_chart(fig, use_container_width=True)

def plot_aggregated_top_keywords(df):
    """
    æ ¹æ®å¤šä¸ªASINçš„æ•°æ®ï¼Œèšåˆè®¡ç®—å¹¶ç»˜åˆ¶æµé‡æœ€é«˜çš„TOP 10å…³é”®è¯ã€‚
    """
    st.subheader("TOP 10 èšåˆæµé‡å…³é”®è¯")
    if df.empty:
        st.warning("å½“å‰ç­›é€‰æ¡ä»¶ä¸‹æ— æ•°æ®ã€‚")
        return

    # æŒ‰â€œæµé‡è¯â€åˆ†ç»„ï¼Œå¹¶åŠ æ€»â€œé¢„ä¼°å‘¨æ›å…‰é‡â€
    top_keywords = df.groupby('æµé‡è¯')['é¢„ä¼°å‘¨æ›å…‰é‡'].sum().sort_values(ascending=False).head(10).reset_index()

    fig = px.bar(
        top_keywords,
        x='é¢„ä¼°å‘¨æ›å…‰é‡',
        y='æµé‡è¯',
        orientation='h',
        title='é¢„ä¼°å‘¨æ›å…‰é‡æœ€é«˜çš„10ä¸ªå…³é”®è¯ (å·²èšåˆ)',
        labels={'é¢„ä¼°å‘¨æ›å…‰é‡': 'é¢„ä¼°å‘¨æ›å…‰é‡æ€»å’Œ', 'æµé‡è¯': 'å…³é”®è¯'},
        text='é¢„ä¼°å‘¨æ›å…‰é‡'
    )
    fig.update_layout(yaxis={'categoryorder':'total ascending'})
    fig.update_traces(texttemplate='%{x:,.0f}', textposition='outside')
    st.plotly_chart(fig, use_container_width=True)


def plot_keyword_type_distribution(df):
    """
    ç»˜åˆ¶å…³é”®è¯ç±»å‹çš„åˆ†å¸ƒé¥¼å›¾ã€‚
    """
    st.subheader("å…³é”®è¯ç±»å‹åˆ†å¸ƒ (å·²èšåˆ)")
    if df.empty:
        st.warning("å½“å‰ç­›é€‰æ¡ä»¶ä¸‹æ— æ•°æ®ã€‚")
        return

    type_counts = df['å…³é”®è¯ç±»å‹'].value_counts().reset_index()
    type_counts.columns = ['å…³é”®è¯ç±»å‹', 'æ•°é‡']

    fig = px.pie(
        type_counts,
        names='å…³é”®è¯ç±»å‹',
        values='æ•°é‡',
        title='å„ç±»å…³é”®è¯æ•°é‡å æ¯”'
    )
    st.plotly_chart(fig, use_container_width=True)


def generate_word_cloud(df):
    """
    æ ¹æ®â€œæµé‡è¯â€ç”Ÿæˆå¹¶å±•ç¤ºè¯äº‘ã€‚
    """
    st.subheader("å…³é”®è¯è¯äº‘ (å·²èšåˆ)")
    if df.empty:
        st.warning("å½“å‰ç­›é€‰æ¡ä»¶ä¸‹æ— æ•°æ®ã€‚")
        return

    text = " ".join(keyword for keyword in df['æµé‡è¯'].dropna().astype(str))
    if not text:
        st.warning("å…³é”®è¯æ•°æ®ä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆè¯äº‘ã€‚")
        return

    wordcloud = WordCloud(width=800, height=400, background_color='white', collocations=False).generate(text)
    fig, ax = plt.subplots()
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    st.pyplot(fig)


# --- 2. Streamlit é¡µé¢ä¸»å‡½æ•° ---

def main():
    """
    å¤šASINåˆ†æé¢æ¿çš„ä¸»å‡½æ•°ã€‚
    """
    st.set_page_config(page_title="å¤šASINå…³é”®è¯åˆ†æé¢æ¿", layout="wide")
    st.title("ğŸ“Š å¤šASINåæŸ¥å…³é”®è¯åˆ†æé¢æ¿")

    # --- ä¾§è¾¹æ  ---
    with st.sidebar:
        st.header("ä¸Šä¼ ä¸ç­›é€‰")
        uploaded_file = st.file_uploader("ä¸Šä¼ åˆå¹¶åçš„Excelæ–‡ä»¶", type=["xlsx"])

        # å ä½ç¬¦ï¼Œç”¨äºä¹‹åæ˜¾ç¤ºASINç­›é€‰å™¨
        filter_container = st.container()

    if uploaded_file is None:
        st.info("ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ï¼è¯·åœ¨å·¦ä¾§ä¸Šä¼ åŒ…å« 'æ€»è¡¨-æ‰€æœ‰ASINæ•´åˆ' Sheetçš„Excelæ–‡ä»¶ä»¥å¼€å§‹åˆ†æã€‚")
        return

    # --- æ•°æ®åŠ è½½ä¸å¤„ç† ---
    df_original = load_merged_data(uploaded_file)
    if df_original is None:
        return # å¦‚æœåŠ è½½å¤±è´¥ï¼Œåˆ™åœæ­¢æ‰§è¡Œ

    # æ¸…æ´—æ•°æ®
    df_cleaned = clean_data(df_original.copy())

    # --- åœ¨ä¾§è¾¹æ ä¸­åŠ¨æ€åˆ›å»ºASINç­›é€‰å™¨ ---
    all_asins = df_cleaned['ASIN'].unique()
    selected_asins = filter_container.multiselect("é€‰æ‹©è¦åˆ†æçš„ASIN (å¯å¤šé€‰)", options=all_asins, default=all_asins)

    # æ ¹æ®é€‰æ‹©ç­›é€‰æ•°æ®
    if selected_asins:
        df_filtered = df_cleaned[df_cleaned['ASIN'].isin(selected_asins)]
    else:
        # å¦‚æœæ²¡æœ‰é€‰æ‹©ä»»ä½•ASINï¼Œåˆ™æ˜¾ç¤ºç©ºçŠ¶æ€
        st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªASINè¿›è¡Œåˆ†æã€‚")
        return

    # --- é¡µé¢ä¸»å†…å®¹å±•ç¤º ---
    display_metrics(df_filtered)
    st.markdown("---")

    # æ–°å¢çš„ASINå¯¹æ¯”å›¾
    if len(selected_asins) > 1: # ä»…åœ¨é€‰æ‹©å¤šä¸ªASINæ—¶æ˜¾ç¤ºå¯¹æ¯”å›¾æ‰æœ‰æ„ä¹‰
        plot_asin_contribution(df_filtered)
        st.markdown("---")

    # èšåˆå›¾è¡¨
    col1, col2 = st.columns(2)
    with col1:
        plot_aggregated_top_keywords(df_filtered)
    with col2:
        plot_keyword_type_distribution(df_filtered)

    generate_word_cloud(df_filtered)
    st.markdown("---")

    # è¯¦ç»†æ•°æ®è¡¨
    st.subheader("è¯¦ç»†æ•°æ®è¡¨ (å·²ç­›é€‰)")
    st.dataframe(df_filtered)

# --- 3. åº”ç”¨å¯åŠ¨ ---

if __name__ == "__main__":
    main()